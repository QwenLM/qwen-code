# Qwen Code - Codebase Index è®¾è®¡æ–‡æ¡£

> **ç‰ˆæœ¬**: v1.4  
> **æ—¥æœŸ**: 2026-01-29  
> **çŠ¶æ€**: è®¾è®¡å®šç¨¿

## 1. æ¦‚è¿°

### 1.1 èƒŒæ™¯ä¸ç›®æ ‡

Qwen Code æ˜¯ä¸€ä¸ªå®Œå…¨å¼€æºã€è½»é‡çº§ã€æ— åç«¯çš„ AI Coding CLI åº”ç”¨ã€‚ä¸ºäº†å¢å¼º AI å¯¹å¤§å‹ä»£ç åº“çš„ç†è§£èƒ½åŠ›ï¼Œæˆ‘ä»¬è®¡åˆ’å¼•å…¥ **Codebase Index** åŠŸèƒ½ï¼Œé€šè¿‡å»ºç«‹ä»£ç åº“çš„å‘é‡ç´¢å¼•ï¼Œå®ç°åŸºäºè¯­ä¹‰çš„ä»£ç æ£€ç´¢ï¼ˆRAGï¼‰å’Œä¸Šä¸‹æ–‡å¢å¼ºã€‚

**ä¸šåŠ¡ç›®æ ‡**ï¼š

- è§£å†³ **FP2ï¼ˆé”™è¿‡é«˜æ’åæ–‡æ¡£ï¼‰**ï¼šé€šè¿‡æ··åˆæ£€ç´¢ç¡®ä¿å…³é”®ä»£ç è¢«å¬å›
- è§£å†³ **FP4ï¼ˆæœªèƒ½æå–ï¼‰**ï¼šé€šè¿‡ç»“æ„æ„ŸçŸ¥åˆ†å—ä¿æŒä»£ç å®Œæ•´æ€§
- è§£å†³ **FP6ï¼ˆç‰¹å¼‚æ€§ä¸æ­£ç¡®ï¼‰**ï¼šé€šè¿‡è”åˆè¯­ä¹‰åµŒå…¥æå‡è·¨è¯­è¨€/æ¨¡ç³ŠæŸ¥è¯¢èƒ½åŠ›
- è§£å†³ **FP7ï¼ˆä¸å®Œæ•´ï¼‰**ï¼šé€šè¿‡çŸ¥è¯†å›¾è°±å®ç°è·¨æ–‡ä»¶ä¾èµ–è¿½è¸ª

**æŠ€æœ¯ç›®æ ‡**ï¼š

- å¸®åŠ© AI ç†è§£å¤§å‹ä»£ç åº“ï¼ˆ10ä¸‡+ æ–‡ä»¶ï¼‰çš„æ•´ä½“ç»“æ„
- æä¾› <500ms çš„è¯­ä¹‰æ£€ç´¢å“åº”æ—¶é—´
- å®ç°ä½å»¶è¿Ÿã€ä½èµ„æºå ç”¨çš„æœ¬åœ°åŒ–ç´¢å¼•æ–¹æ¡ˆ
- æ”¯æŒä»£ç å˜æ›´æ—¶çš„å¿«é€Ÿå¢é‡æ›´æ–°

### 1.2 è®¾è®¡åŸåˆ™

1. **æœ¬åœ°åŒ–ä¼˜å…ˆ**ï¼šæ‰€æœ‰æ•°æ®å­˜å‚¨å’Œè®¡ç®—éƒ½åœ¨æœ¬åœ°å®Œæˆï¼Œæ— éœ€åç«¯æœåŠ¡
2. **è½»é‡çº§**ï¼šæœ€å°åŒ–å†…å­˜ï¼ˆ<500MBï¼‰å’Œç£ç›˜å ç”¨ï¼Œä¸å½±å“å¼€å‘ç¯å¢ƒæ€§èƒ½
3. **å¢é‡æ›´æ–°**ï¼šåªå¤„ç†å˜æ›´çš„æ–‡ä»¶ï¼Œé¿å…å…¨é‡é‡å»º
4. **éé˜»å¡**ï¼šç´¢å¼•æ„å»ºåœ¨åå° Worker çº¿ç¨‹è¿›è¡Œï¼Œä¸é˜»å¡ä¸»äº¤äº’æµç¨‹
5. **çº¯ TypeScript**ï¼šä½¿ç”¨çº¯ TypeScript + NAPI å®ç°ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•
6. **æ¶æ„ä¸€è‡´æ€§**ï¼šéµå¾ª qwen-code ç°æœ‰çš„æœåŠ¡ç±»è®¾è®¡æ¨¡å¼å’Œä»£ç é£æ ¼
7. **å¤ç”¨ä¼˜å…ˆ**ï¼šä¼˜å…ˆä½¿ç”¨ qwen-code ç°æœ‰çš„å·¥å…·æ–¹æ³•ï¼Œé¿å…é‡å¤é€ è½®å­

### 1.3 å¹³å°æ”¯æŒ

> âš ï¸ **å½“å‰ç‰ˆæœ¬ä»…æ”¯æŒ macOS å’Œ Linux å¹³å°ï¼Œä¸æ”¯æŒ Windowsã€‚**

ç”±äº Zvec NAPI åŸç”Ÿæ¨¡å—çš„é™åˆ¶ï¼ŒCodebase Index åŠŸèƒ½æš‚ä¸æ”¯æŒ Windows å¹³å°ã€‚åœ¨åŠŸèƒ½çš„å„ä¸ªå…¥å£å¤„éœ€è¦è¿›è¡Œå¹³å°æ£€æŸ¥ã€‚

**æ”¯æŒçš„å¹³å°ï¼š**

- macOS (darwin) - x64, arm64
- Linux (linux) - x64, arm64

**ä¸æ”¯æŒçš„å¹³å°ï¼š**

- Windows (win32) - æ‰€æœ‰æ¶æ„

**å¹³å°æ£€æŸ¥**ï¼šå¤ç”¨ qwen-code ç°æœ‰çš„ `isWindows` å·¥å…·

```typescript
// å¤ç”¨ç°æœ‰çš„å¹³å°å·¥å…·
// æ¥æº: packages/vscode-ide-companion/src/utils/platform.ts
// æˆ– packages/cli/src/ui/utils/platformConstants.ts

import { isWindows } from '../utils/platform.js';

// åœ¨åŠŸèƒ½å…¥å£å¤„ç›´æ¥ä½¿ç”¨ isWindows è¿›è¡Œæ£€æŸ¥:
if (isWindows) {
  // è¿”å›ä¸æ”¯æŒçš„é”™è¯¯ä¿¡æ¯
  return {
    type: 'message',
    messageType: 'error',
    content: 'âŒ Codebase Index åŠŸèƒ½æš‚ä¸æ”¯æŒ Windows å¹³å°',
  };
}
```

---

## 2. æ•´ä½“æ¶æ„

### 2.1 ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              Qwen Code CLI (Main Thread)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  /codebase  â”‚â”€â”€â”€â–¶â”‚   Retrieval     â”‚â”€â”€â”€â–¶â”‚     Context Builder        â”‚    â”‚
â”‚  â”‚   Command   â”‚    â”‚   Coordinator   â”‚    â”‚  (Token Budget Management) â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚        â”‚                    â”‚                           â”‚                     â”‚
â”‚        â”‚                    â–¼                           â–¼                     â”‚
â”‚        â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚        â”‚           â”‚  Query Enhancer â”‚          â”‚     LLM     â”‚              â”‚
â”‚        â”‚           â”‚ (Multi-Query)   â”‚          â”‚   Request   â”‚              â”‚
â”‚        â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚        â”‚                    â”‚                                                 â”‚
â”‚        â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚        â”‚    â”‚               â”‚               â”‚                                 â”‚
â”‚        â”‚    â–¼               â–¼               â–¼                                 â”‚
â”‚        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚        â”‚ â”‚ BM25 â”‚     â”‚  Vector  â”‚    â”‚ Recently â”‚     Hybrid Search         â”‚
â”‚        â”‚ â”‚ FTS  â”‚     â”‚  Search  â”‚    â”‚  Edited  â”‚     with RRF Fusion       â”‚
â”‚        â”‚ â””â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚        â”‚    â”‚               â”‚               â”‚                                 â”‚
â”‚        â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚        â”‚                    â”‚                                                 â”‚
â”‚        â”‚                    â–¼                                                 â”‚
â”‚        â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚        â”‚           â”‚    Reranker     â”‚  (Cross-Encoder, Optional)            â”‚
â”‚        â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚        â”‚                                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        â”‚                      IPC Channel (MessagePort)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        â”‚                                                                      â”‚
â”‚        â”‚                     Worker Thread (IndexWorker)                      â”‚
â”‚        â–¼                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         IndexManager                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚ FileScanner â”‚  â”‚   Chunker   â”‚  â”‚  Embedder   â”‚  â”‚ ChangeDetectorâ”‚   â”‚ â”‚
â”‚  â”‚  â”‚ (ripgrep)   â”‚  â”‚ (AST-based) â”‚  â”‚ (Qwen API)  â”‚  â”‚ (10min poll)  â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                        â”‚                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                        â”‚         Storage Layer                â”‚
â”‚                                        â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                          SQLite (better-sqlite3)                         â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚  file_meta    â”‚  â”‚    chunks     â”‚  â”‚   fts_chunks (FTS5)       â”‚    â”‚ â”‚
â”‚  â”‚  â”‚  (hash, mtime)â”‚  â”‚ (content,line)â”‚  â”‚   (BM25 full-text)        â”‚    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         Zvec (NAPI Binding)                              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  Collection: codebase_vectors                                      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Dense Vector: content_embedding (1024 dim, HNSW, Cosine)       â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Scalar Fields: chunk_id, file_path, branch                     â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ ¸å¿ƒæ¨¡å—èŒè´£

> **æ¶æ„è¯´æ˜**ï¼šéµå¾ª qwen-code ç°æœ‰çš„æœåŠ¡ç±»è®¾è®¡æ¨¡å¼ï¼Œä½¿ç”¨ `*Service` åç¼€å‘½åæœåŠ¡ç±»ï¼Œæ¥å£ä½¿ç”¨ `I*` å‰ç¼€ã€‚æ ¸å¿ƒæ¨¡å—æ”¾ç½®åœ¨ `packages/core/src/indexing/`ï¼ŒCLI é›†æˆæ”¾ç½®åœ¨ `packages/cli/src/`ã€‚ä¼˜å…ˆå¤ç”¨ç°æœ‰å·¥å…·ï¼ˆå¦‚ `FileDiscoveryService`ã€`ripgrepUtils`ã€`isWindows` ç­‰ï¼‰ã€‚

| æ¨¡å—                 | æ‰€åœ¨çº¿ç¨‹ | èŒè´£                                         | å…³é”®ç±»/æ–‡ä»¶                                          |
| -------------------- | -------- | -------------------------------------------- | ---------------------------------------------------- |
| **IndexService**     | Main     | ç´¢å¼•æœåŠ¡é—¨é¢ï¼Œç®¡ç† Worker ç”Ÿå‘½å‘¨æœŸ           | `packages/core/src/indexing/indexService.ts`         |
| **IndexManager**     | Worker   | ç´¢å¼•ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œåè°ƒå„ç»„ä»¶                 | `packages/core/src/indexing/indexManager.ts`         |
| **FileScanner**      | Worker   | å¤ç”¨ `FileDiscoveryService` + `ripgrepUtils` | `packages/core/src/indexing/fileScanner.ts`          |
| **ChunkingService**  | Worker   | AST åˆ†å— + æ»‘åŠ¨çª—å£ fallback                 | `packages/core/src/indexing/chunkingService.ts`      |
| **EmbeddingService** | Worker   | æ‰¹é‡è°ƒç”¨ Embedding API                       | `packages/core/src/indexing/embeddingService.ts`     |
| **ChangeDetector**   | Worker   | å®šæ—¶è½®è¯¢æ£€æµ‹å˜æ›´                             | `packages/core/src/indexing/changeDetector.ts`       |
| **RetrievalService** | Main     | å¤šè·¯å¬å› + RRF èåˆ + å›¾æ‰©å±•                 | `packages/core/src/indexing/retrievalService.ts`     |
| **MetadataStore**    | Both     | SQLite å…ƒæ•°æ® + FTS å­˜å‚¨                     | `packages/core/src/indexing/stores/metadataStore.ts` |
| **VectorStore**      | Both     | Zvec å‘é‡å­˜å‚¨                                | `packages/core/src/indexing/stores/vectorStore.ts`   |
| **GraphStore**       | Both     | RuVector ä¾èµ–å›¾è°±å­˜å‚¨                        | `packages/core/src/indexing/stores/graphStore.ts`    |
| **EntityExtractor**  | Worker   | AST å®ä½“æå–ï¼ˆå‡½æ•°/ç±»/æ¨¡å—ï¼‰                 | `packages/core/src/indexing/entityExtractor.ts`      |
| **GraphTraverser**   | Main     | å›¾éå†ä¸å­å›¾æå–                             | `packages/core/src/indexing/graphTraverser.ts`       |

### 2.3 æ•°æ®æµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ç´¢å¼•æ„å»ºæ•°æ®æµ                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  [æ–‡ä»¶ç³»ç»Ÿ]                                                                   â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â–¼                                                                       â”‚
â”‚  FileScanner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚
â”‚  â”œâ”€ ripgrep æ‰«æ (å¹¶è¡Œ, æ’é™¤ .gitignore/.qwenignore)                         â”‚
â”‚  â”œâ”€ è®¡ç®— SHA-256 hash                                                        â”‚
â”‚  â””â”€ è¾“å‡º: FileMetadata[]  (path, hash, mtime, size, language)               â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â–¼  æ‰¹é‡å¤„ç†: 100 files/batch                                            â”‚
â”‚  Chunker â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚
â”‚  â”œâ”€ Tree-sitter AST è§£æ (å‡½æ•°/ç±»/æ¨¡å—è¾¹ç•Œ)                                  â”‚
â”‚  â”œâ”€ æ»‘åŠ¨çª—å£ fallback (512 tokens, 50 tokens overlap)                       â”‚
â”‚  â””â”€ è¾“å‡º: Chunk[] (content, startLine, endLine, type, metadata)             â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â–¼  æ‰¹é‡å¤„ç†: 20 chunks/batch, 10 å¹¶å‘ (p-map)                          â”‚
â”‚  Embedder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
â”‚  â”œâ”€ è°ƒç”¨ BaseLlmClient.generateEmbedding()                                   â”‚
â”‚  â”œâ”€ ä½¿ç”¨ text-embedding-v4 (1024 dim)                                        â”‚
â”‚  â”œâ”€ å¹¶å‘æ§åˆ¶: maxConcurrency=10, timeout=30s                                 â”‚
â”‚  â””â”€ è¾“å‡º: number[][] (embeddings)                                            â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â–¼  æ‰¹é‡å†™å…¥: 500 records/batch                                          â”‚
â”‚  Storage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚
â”‚  â”œâ”€ SQLite: file_meta, chunks, fts_chunks                                    â”‚
â”‚  â””â”€ Zvec: collection.insert() with vectors                                   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. åŠŸèƒ½è®¾è®¡

### 3.1 ç´¢å¼•æ„å»º

#### 3.1.1 è§¦å‘æ—¶æœºä¸å¼€å…³æ§åˆ¶

```typescript
// packages/core/src/indexing/types.ts

interface IndexConfig {
  enabled: boolean; // æ€»å¼€å…³ï¼Œå…³é—­æ—¶ä¸è¿›è¡Œä»»ä½•ç´¢å¼•æ“ä½œ
  autoIndex: boolean; // æ˜¯å¦è‡ªåŠ¨ç´¢å¼•æ–°é¡¹ç›®
  pollIntervalMs: number; // å˜æ›´æ£€æµ‹é—´éš”ï¼Œé»˜è®¤ 600000 (10åˆ†é’Ÿ)
}
```

| è§¦å‘åœºæ™¯     | æ¡ä»¶                                             | è¡Œä¸º                         |
| ------------ | ------------------------------------------------ | ---------------------------- |
| é¦–æ¬¡è¿›å…¥é¡¹ç›® | `enabled=true && autoIndex=true && !indexExists` | åå°å¯åŠ¨å…¨é‡æ„å»º             |
| æ‰‹åŠ¨è§¦å‘     | `/codebase build` å‘½ä»¤                           | åå°å¯åŠ¨å…¨é‡é‡å»º             |
| å®šæ—¶è½®è¯¢     | `enabled=true && indexExists`                    | æ¯ 10 åˆ†é’Ÿæ£€æµ‹å˜æ›´ï¼Œå¢é‡æ›´æ–° |
| ç´¢å¼•å…³é—­     | `enabled=false`                                  | åœæ­¢è½®è¯¢ï¼Œä¸æ¥å—æ„å»ºè¯·æ±‚     |

#### 3.1.2 æ„å»ºæµç¨‹è¯¦ç»†è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ç´¢å¼•æ„å»ºæµæ°´çº¿ (Worker Thread)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  é˜¶æ®µ1: æ–‡ä»¶æ‰«æ (FileScanner)                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ è¾“å…¥: projectRoot, ignorePatterns                                    â”‚    â”‚
â”‚  â”‚ å¤„ç†:                                                                â”‚    â”‚
â”‚  â”‚   1. è°ƒç”¨ ripgrep --files (å¤ç”¨ ripgrepUtils.ts)                     â”‚    â”‚
â”‚  â”‚   2. è¿‡æ»¤: .gitignore + .qwenignore + äºŒè¿›åˆ¶æ–‡ä»¶                     â”‚    â”‚
â”‚  â”‚   3. å¹¶è¡Œè®¡ç®— SHA-256 hash (4 å¹¶å‘, crypto.createHash)               â”‚    â”‚
â”‚  â”‚ è¾“å‡º: FileMetadata[] (~10,000 files/sec on SSD)                      â”‚    â”‚
â”‚  â”‚ æ‰¹é‡: å…¨é‡æ‰«æä¸€æ¬¡æ€§å®Œæˆ                                              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                               â”‚                                              â”‚
â”‚                               â–¼                                              â”‚
â”‚  é˜¶æ®µ2: ä»£ç åˆ†å— (Chunker)                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ è¾“å…¥: FileMetadata[]                                                 â”‚    â”‚
â”‚  â”‚ å¤„ç†:                                                                â”‚    â”‚
â”‚  â”‚   1. æŒ‰è¯­è¨€é€‰æ‹©è§£æç­–ç•¥ (Tree-sitter AST / è¡Œåˆ†å‰²)                    â”‚    â”‚
â”‚  â”‚   2. AST åˆ†å—: å‡½æ•°ã€ç±»ã€æ¨¡å—ä¸ºå•ä½                                   â”‚    â”‚
â”‚  â”‚   3. è¶…å¤§å—é€’å½’åˆ†å‰² (>512 tokens), ä¿ç•™ 50 tokens é‡å                 â”‚    â”‚
â”‚  â”‚   4. ç”Ÿæˆå…ƒæ•°æ®: startLine, endLine, type, imports                    â”‚    â”‚
â”‚  â”‚ è¾“å‡º: Chunk[]                                                        â”‚    â”‚
â”‚  â”‚ æ‰¹é‡: 100 files/batch, å¤„ç†å®Œä¸€æ‰¹å†™å…¥ SQLite åç»§ç»­                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                               â”‚                                              â”‚
â”‚                               â–¼                                              â”‚
â”‚  é˜¶æ®µ3: Embedding ç”Ÿæˆ (Embedder)                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ è¾“å…¥: Chunk[]                                                        â”‚    â”‚
â”‚  â”‚ å¤„ç†:                                                                â”‚    â”‚
â”‚  â”‚   1. æŸ¥è¯¢ embedding_cache (SQLite), å‘½ä¸­åˆ™è·³è¿‡                        â”‚    â”‚
â”‚  â”‚   2. æ„å»º embedding è¾“å…¥: [filepath, content, metadata].join('\\n')   â”‚    â”‚
â”‚  â”‚   3. å¹¶å‘è°ƒç”¨ BaseLlmClient.generateEmbedding() (p-map)              â”‚    â”‚
â”‚  â”‚   4. å†™å…¥ embedding_cache                                            â”‚    â”‚
â”‚  â”‚ è¾“å‡º: {chunkId, embedding}[]                                         â”‚    â”‚
â”‚  â”‚ æ‰¹é‡: 20 chunks/batch, 10 å¹¶å‘, 30s è¶…æ—¶, å¤±è´¥è‡ªåŠ¨é‡è¯•               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                               â”‚                                              â”‚
â”‚                               â–¼                                              â”‚
â”‚  é˜¶æ®µ4: å­˜å‚¨å†™å…¥ (StorageWriter)                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ è¾“å…¥: Chunk[] with embeddings                                        â”‚    â”‚
â”‚  â”‚ å¤„ç†:                                                                â”‚    â”‚
â”‚  â”‚   1. SQLite äº‹åŠ¡å†™å…¥ (chunks è¡¨ + fts_chunks è™šæ‹Ÿè¡¨)                  â”‚    â”‚
â”‚  â”‚   2. Zvec collection.insert() æ‰¹é‡å†™å…¥                                â”‚    â”‚
â”‚  â”‚ è¾“å‡º: å†™å…¥æˆåŠŸçš„ chunk count                                          â”‚    â”‚
â”‚  â”‚ æ‰¹é‡: 500 records/batch (SQLite), 100 docs/batch (Zvec)              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.1.3 è¿›åº¦åé¦ˆä¸æ§åˆ¶

```typescript
// packages/core/src/indexing/types.ts
interface IndexingProgress {
  status:
    | 'idle'
    | 'scanning'
    | 'chunking'
    | 'embedding'
    | 'storing'
    | 'done'
    | 'paused'
    | 'error';
  phase: number; // 1-4 å¯¹åº”ä¸Šè¿°å››ä¸ªé˜¶æ®µ
  phaseProgress: number; // å½“å‰é˜¶æ®µè¿›åº¦ 0-100
  overallProgress: number; // æ€»ä½“è¿›åº¦ 0-100

  // é˜¶æ®µæ€§æ•°æ®
  scannedFiles: number;
  totalFiles: number;
  chunkedFiles: number;
  embeddedChunks: number;
  totalChunks: number;
  storedChunks: number;

  // æ—¶é—´ä¼°ç®—
  startTime: number;
  estimatedTimeRemaining?: number; // seconds

  // é”™è¯¯ä¿¡æ¯
  error?: string;
  failedFiles?: string[];
}

// Worker -> Main è¿›åº¦æ¶ˆæ¯
interface IndexProgressMessage {
  type: 'progress';
  payload: IndexingProgress;
}

// Main -> Worker æ§åˆ¶æ¶ˆæ¯
interface IndexControlMessage {
  type: 'pause' | 'resume' | 'cancel' | 'rebuild';
}
```

**UI æ˜¾ç¤ºæ ¼å¼**ï¼š

```
ç´¢å¼•çŠ¶æ€æ˜¾ç¤º:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š Codebase Index                                               â”‚
â”‚ â”œâ”€ Status: Building (Phase 3/4: Embedding)                     â”‚
â”‚ â”œâ”€ Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 42%                          â”‚
â”‚ â”œâ”€ Files: 1,234 / 2,891 chunked                                â”‚
â”‚ â”œâ”€ Chunks: 4,521 / 10,800 embedded                             â”‚
â”‚ â””â”€ ETA: ~3 minutes remaining                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 å˜æ›´æ£€æµ‹ä¸å¢é‡æ›´æ–°

#### 3.2.1 å®šæ—¶è½®è¯¢æœºåˆ¶

> **è®¾è®¡å†³ç­–**ï¼šé‡‡ç”¨çº¯è½®è¯¢è€Œéå®æ—¶æ–‡ä»¶ç›‘å¬ï¼ˆfs.watchï¼‰ã€‚ç†ç”±ï¼š
>
> 1. **æ€§èƒ½ä¼˜å…ˆ**ï¼šfs.watch åœ¨å¤§å‹ä»£ç åº“ä¸­ä¼šäº§ç”Ÿæ˜¾è‘—çš„ CPU å’Œå†…å­˜å¼€é”€
> 2. **ç¨³å®šæ€§**ï¼šä¸åŒæ“ä½œç³»ç»Ÿçš„ fs.watch è¡Œä¸ºä¸ä¸€è‡´ï¼Œå­˜åœ¨å…¼å®¹æ€§é—®é¢˜
> 3. **CLI åœºæ™¯ç‰¹ç‚¹**ï¼šç”¨æˆ·ä¸»åŠ¨å‘èµ·æ“ä½œï¼Œ10 åˆ†é’Ÿè½®è¯¢é—´éš”è¶³å¤Ÿå“åº”éœ€æ±‚
> 4. **å¯é¢„æµ‹æ€§**ï¼šè½®è¯¢è¡Œä¸ºç¡®å®šï¼Œä¾¿äºè°ƒè¯•å’Œæ€§èƒ½åˆ†æ

```typescript
// packages/core/src/indexing/changeDetector.ts

/**
 * Detects file changes in the workspace and triggers incremental index updates.
 * Uses a polling-based approach for stability and predictable performance.
 */
class ChangeDetector {
  private pollTimer: NodeJS.Timeout | null = null;
  private readonly POLL_INTERVAL = 10 * 60 * 1000; // 10 minutes

  /**
   * Starts the periodic change detection polling.
   * @param config The index configuration.
   */
  start(config: IndexConfig): void {
    if (!config.enabled) {
      return; // ç´¢å¼•å…³é—­æ—¶ä¸å¯åŠ¨è½®è¯¢
    }

    this.pollTimer = setInterval(() => {
      this.detectAndUpdate();
    }, this.POLL_INTERVAL);
  }

  /**
   * Stops the periodic change detection polling.
   */
  stop(): void {
    if (this.pollTimer) {
      clearInterval(this.pollTimer);
      this.pollTimer = null;
    }
  }

  /**
   * Detects file changes and triggers incremental update if needed.
   */
  async detectAndUpdate(): Promise<void> {
    // 1. æ‰«æå½“å‰æ–‡ä»¶çŠ¶æ€
    const currentFiles = await this.scanCurrentFiles();

    // 2. åŠ è½½å·²ç´¢å¼•æ–‡ä»¶çš„ hash
    const indexedFiles = await this.loadIndexedFileHashes();

    // 3. å¯¹æ¯”è®¡ç®—å˜æ›´
    const changes = this.computeChanges(currentFiles, indexedFiles);

    // 4. å¦‚æœæœ‰å˜æ›´ï¼Œè§¦å‘å¢é‡æ›´æ–°
    if (changes.hasChanges()) {
      await this.applyIncrementalUpdate(changes);
    }
  }
}
```

#### 3.2.2 å˜æ›´æ£€æµ‹ç®—æ³•

```typescript
// packages/core/src/indexing/types.ts
interface FileMetadata {
  path: string;
  contentHash: string;     // SHA-256ï¼Œåªåœ¨ mtime å˜åŒ–æ—¶é‡ç®—
  lastModified: number;    // fs.stat.mtimeMs
  size: number;
}

interface ChangeSet {
  added: FileMetadata[];      // æ–°å¢æ–‡ä»¶
  modified: FileMetadata[];   // ä¿®æ”¹çš„æ–‡ä»¶ (hash å˜åŒ–)
  deleted: string[];          // åˆ é™¤çš„æ–‡ä»¶è·¯å¾„

  hasChanges(): boolean {
    return this.added.length > 0 || this.modified.length > 0 || this.deleted.length > 0;
  }
}

// packages/core/src/indexing/changeDetector.ts
function computeChanges(
  current: Map<string, FileMetadata>,
  indexed: Map<string, FileMetadata>
): ChangeSet {
  const result: ChangeSet = { added: [], modified: [], deleted: [] };

  // O(n) éå†å½“å‰æ–‡ä»¶
  for (const [path, currentMeta] of current) {
    const indexedMeta = indexed.get(path);

    if (!indexedMeta) {
      // æ–°å¢æ–‡ä»¶
      result.added.push(currentMeta);
    } else if (currentMeta.lastModified > indexedMeta.lastModified) {
      // mtime å˜åŒ–ï¼Œæ£€æŸ¥ hash
      if (currentMeta.contentHash !== indexedMeta.contentHash) {
        result.modified.push(currentMeta);
      }
    }
  }

  // O(m) æ£€æµ‹åˆ é™¤
  for (const path of indexed.keys()) {
    if (!current.has(path)) {
      result.deleted.push(path);
    }
  }

  return result;
}
```

#### 3.2.3 å¢é‡æ›´æ–°æ‰§è¡Œ

```typescript
// packages/core/src/indexing/changeDetector.ts
async function applyIncrementalUpdate(changes: ChangeSet): Promise<void> {
  const { added, modified, deleted } = changes;

  // 1. åˆ é™¤æ“ä½œ (æœ€å¿«, å…ˆæ‰§è¡Œ)
  if (deleted.length > 0) {
    await db.run(
      `DELETE FROM chunks WHERE file_path IN (${deleted.map(() => '?').join(',')})`,
      deleted,
    );
    await db.run(
      `DELETE FROM file_meta WHERE path IN (${deleted.map(() => '?').join(',')})`,
      deleted,
    );
    // Zvec æŒ‰ file_path filter åˆ é™¤
    for (const path of deleted) {
      await collection.delete({ filter: `file_path = '${path}'` });
    }
  }

  // 2. ä¿®æ”¹æ“ä½œ (å…ˆåˆ ååŠ )
  if (modified.length > 0) {
    const modifiedPaths = modified.map((m) => m.path);
    await db.run(
      `DELETE FROM chunks WHERE file_path IN (${modifiedPaths.map(() => '?').join(',')})`,
      modifiedPaths,
    );
    // Zvec åˆ é™¤
    for (const path of modifiedPaths) {
      await collection.delete({ filter: `file_path = '${path}'` });
    }
  }

  // 3. æ–°å¢ + ä¿®æ”¹ ç»Ÿä¸€èµ° chunking -> embedding -> storage æµç¨‹
  const filesToProcess = [...added, ...modified];
  if (filesToProcess.length > 0) {
    await this.indexFiles(filesToProcess);
  }
}
```

### 3.3 åˆ†æ”¯åˆ‡æ¢å¤„ç†

ç”±äº qwen-code æ˜¯ CLI å·¥å…·ï¼Œæ¯æ¬¡å¯åŠ¨å¯èƒ½å¤„äºä¸åŒåˆ†æ”¯ã€‚æˆ‘ä»¬é‡‡ç”¨**å•ç´¢å¼• + åˆ†æ”¯æ ‡è®°**ç­–ç•¥ï¼ˆè€Œéå¤šåˆ†æ”¯ç‹¬ç«‹ç´¢å¼•ï¼‰ï¼Œå› ä¸ºï¼š

1. é¿å…ç£ç›˜ç©ºé—´çˆ†ç‚¸ï¼ˆæ¯ä¸ªåˆ†æ”¯ä¸€ä»½ç´¢å¼•ï¼‰
2. å¤§å¤šæ•°åˆ†æ”¯é—´å·®å¼‚ <10%ï¼Œå¢é‡æ›´æ–°æ›´é«˜æ•ˆ
3. CLI åœºæ™¯ä¸‹ç”¨æˆ·é€šå¸¸å…³æ³¨å½“å‰åˆ†æ”¯

```typescript
// packages/core/src/indexing/branchHandler.ts

class BranchHandler {
  private lastBranch: string | null = null;

  async checkBranchChange(): Promise<void> {
    const currentBranch = await this.getCurrentBranch();

    if (this.lastBranch && this.lastBranch !== currentBranch) {
      // åˆ†æ”¯å‘ç”Ÿåˆ‡æ¢ï¼Œç«‹å³è§¦å‘å˜æ›´æ£€æµ‹
      await this.changeDetector.detectAndUpdate();
    }

    this.lastBranch = currentBranch;
  }

  private async getCurrentBranch(): Promise<string> {
    // å¤ç”¨ gitService.ts
    const { stdout } = await exec('git rev-parse --abbrev-ref HEAD');
    return stdout.trim();
  }
}
```

**åˆ†æ”¯åˆ‡æ¢è§¦å‘æ—¶æœº**ï¼š

- åº”ç”¨å¯åŠ¨æ—¶æ£€æµ‹
- æ¯æ¬¡ 10 åˆ†é’Ÿè½®è¯¢æ—¶æ£€æµ‹
- `/codebase status` å‘½ä»¤æ—¶æ£€æµ‹

### 3.4 RAG æ£€ç´¢

#### 3.4.1 æ··åˆæ£€ç´¢æ¶æ„ (Hybrid Search)

åŸºäºä¸šç•Œæœ€ä½³å®è·µï¼ˆå‚è€ƒ DeepWiki RAGï¼‰ï¼Œæˆ‘ä»¬é‡‡ç”¨ **BM25 + å‘é‡ + æœ€è¿‘ç¼–è¾‘** ä¸‰è·¯å¬å› + **RRF èåˆ**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          æ£€ç´¢æµæ°´çº¿ (Main Thread)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ç”¨æˆ·æŸ¥è¯¢: "å¦‚ä½•å®ç°æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½"                                              â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â–¼                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ æŸ¥è¯¢å¢å¼º (QueryEnhancer) - å¯é€‰ï¼ŒPhase 2                             â”‚    â”‚
â”‚  â”‚ â”œâ”€ åŒä¹‰è¯æ‰©å±•: "æ–‡ä»¶ä¸Šä¼ " â†’ ["file upload", "ä¸Šä¼ æ–‡ä»¶", "upload"]     â”‚    â”‚
â”‚  â”‚ â””â”€ æ¡†æ¶æœ¯è¯­: â†’ ["multer", "formidable", "FormData"]                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚      â”‚                                                                       â”‚
â”‚      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚      â–¼                    â–¼                    â–¼                    â–¼       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  BM25  â”‚          â”‚ Vector â”‚          â”‚ Recent â”‚          â”‚ Import â”‚    â”‚
â”‚  â”‚  FTS   â”‚          â”‚ Search â”‚          â”‚ Files  â”‚          â”‚ Graph  â”‚    â”‚
â”‚  â”‚ top=50 â”‚          â”‚ top=50 â”‚          â”‚ top=20 â”‚          â”‚(Phase2)â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚      â”‚                    â”‚                    â”‚                    â”‚       â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                   â”‚                                          â”‚
â”‚                                   â–¼                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚   RRF Fusion (k=60)         â”‚                          â”‚
â”‚                    â”‚   score = Î£ 1/(k + rank_i)  â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                   â”‚                                          â”‚
â”‚                                   â–¼                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚   Reranker (Optional)       â”‚                          â”‚
â”‚                    â”‚   Cross-Encoder ç²¾æ’ top=20 â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                   â”‚                                          â”‚
â”‚                                   â–¼                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚   Context Builder           â”‚                          â”‚
â”‚                    â”‚   Token Budget: 8000        â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.4.2 å„è·¯å¬å›å®ç°

```typescript
// packages/core/src/indexing/retrievalService.ts

interface RetrievalConfig {
  topK: number; // æœ€ç»ˆè¿”å›æ•°é‡ï¼Œé»˜è®¤ 20
  bm25TopK: number; // BM25 å¬å›æ•°é‡ï¼Œé»˜è®¤ 50
  vectorTopK: number; // å‘é‡å¬å›æ•°é‡ï¼Œé»˜è®¤ 50
  recentTopK: number; // æœ€è¿‘ç¼–è¾‘å¬å›ï¼Œé»˜è®¤ 20
  rrfK: number; // RRF å‚æ•°ï¼Œé»˜è®¤ 60
  maxTokens: number; // ä¸Šä¸‹æ–‡ token é™åˆ¶ï¼Œé»˜è®¤ 8000
  enableReranker: boolean; // æ˜¯å¦å¯ç”¨é‡æ’ï¼Œé»˜è®¤ false
}

class RetrievalCoordinator {
  async retrieve(
    query: string,
    config: RetrievalConfig,
  ): Promise<RetrievalResult[]> {
    // 1. å¹¶è¡Œæ‰§è¡Œä¸‰è·¯å¬å›
    const [bm25Results, vectorResults, recentResults] = await Promise.all([
      this.bm25Search(query, config.bm25TopK),
      this.vectorSearch(query, config.vectorTopK),
      this.recentFilesSearch(config.recentTopK),
    ]);

    // 2. RRF èåˆ
    const fused = this.rrfFusion(
      [
        { results: bm25Results, weight: 1.0 },
        { results: vectorResults, weight: 1.0 },
        { results: recentResults, weight: 0.5 },
      ],
      config.rrfK,
    );

    // 3. å¯é€‰é‡æ’
    let ranked = fused.slice(0, config.topK * 2);
    if (config.enableReranker) {
      ranked = await this.rerank(query, ranked);
    }

    // 4. Token é¢„ç®—è£å‰ª
    return this.trimToTokenBudget(
      ranked.slice(0, config.topK),
      config.maxTokens,
    );
  }

  // BM25 å…¨æ–‡æ£€ç´¢ (SQLite FTS5)
  private async bm25Search(
    query: string,
    topK: number,
  ): Promise<ScoredChunk[]> {
    const results = await this.db.all(
      `
      SELECT 
        c.id, c.file_path, c.content, c.start_line, c.end_line,
        bm25(fts_chunks) as score
      FROM fts_chunks
      JOIN chunks c ON fts_chunks.rowid = c.id
      WHERE fts_chunks MATCH ?
      ORDER BY score
      LIMIT ?
    `,
      [this.tokenizeQuery(query), topK],
    );

    return results.map((r, i) => ({ ...r, rank: i + 1 }));
  }

  // å‘é‡æ£€ç´¢ (Zvec)
  private async vectorSearch(
    query: string,
    topK: number,
  ): Promise<ScoredChunk[]> {
    // ç”ŸæˆæŸ¥è¯¢å‘é‡
    const queryEmbedding = await this.llmClient.generateEmbedding([query]);

    // Zvec æŸ¥è¯¢
    const results = this.collection.query({
      fieldName: 'content_embedding',
      topk: topK,
      vector: new Float32Array(queryEmbedding[0]),
    });

    return results.map((r, i) => ({
      id: r.fields.chunk_id,
      file_path: r.fields.file_path,
      score: r.score,
      rank: i + 1,
    }));
  }

  // RRF èåˆç®—æ³•
  private rrfFusion(
    sources: Array<{ results: ScoredChunk[]; weight: number }>,
    k: number,
  ): ScoredChunk[] {
    const scores = new Map<string, number>();
    const chunks = new Map<string, ScoredChunk>();

    for (const { results, weight } of sources) {
      for (const chunk of results) {
        const id = chunk.id;
        const rrfScore = weight / (k + chunk.rank);
        scores.set(id, (scores.get(id) || 0) + rrfScore);
        chunks.set(id, chunk);
      }
    }

    return Array.from(scores.entries())
      .sort((a, b) => b[1] - a[1])
      .map(([id, score]) => ({ ...chunks.get(id)!, fusedScore: score }));
  }
}
```

#### 3.4.3 `/codebase` Slash Command

```typescript
// packages/cli/src/ui/commands/codebaseCommand.ts

import type { SlashCommand, SlashCommandProcessorResult } from '../types.js';

export const codebaseCommand: SlashCommand = {
  name: 'codebase',
  description: 'Search and retrieve relevant code from the indexed codebase',

  subCommands: [
    {
      name: 'query',
      description: 'Search codebase with a natural language query',
      // ç”¨æ³•: /codebase query å¦‚ä½•å®ç°æ–‡ä»¶ä¸Šä¼ 
    },
    {
      name: 'status',
      description: 'Show current indexing status',
      // ç”¨æ³•: /codebase status
    },
    {
      name: 'build',
      description: 'Start or restart index building',
      // ç”¨æ³•: /codebase build
    },
    {
      name: 'pause',
      description: 'Pause ongoing index building',
      // ç”¨æ³•: /codebase pause
    },
    {
      name: 'resume',
      description: 'Resume paused index building',
      // ç”¨æ³•: /codebase resume
    },
    {
      name: 'disable',
      description: 'Disable codebase indexing',
      // ç”¨æ³•: /codebase disable
    },
    {
      name: 'enable',
      description: 'Enable codebase indexing',
      // ç”¨æ³•: /codebase enable
    },
  ],

  async action(context, args): Promise<SlashCommandProcessorResult> {
    // å¹³å°æ”¯æŒæ€§æ£€æŸ¥ï¼ˆå¤ç”¨å·²æœ‰å·¥å…·ï¼‰
    if (isWindows) {
      return {
        type: 'message',
        messageType: 'error',
        content: 'âŒ Codebase Index åŠŸèƒ½æš‚ä¸æ”¯æŒ Windows å¹³å°',
      };
    }

    const [subCommand, ...queryParts] = args;
    const indexService = context.services.indexService;

    switch (subCommand) {
      case 'query':
      case undefined: {
        // é»˜è®¤è¡Œä¸ºï¼šæ£€ç´¢å¹¶æ³¨å…¥ä¸Šä¸‹æ–‡
        const query = queryParts.join(' ') || context.currentInput;
        const results = await indexService.retrieve(query);
        const contextContent = buildCodebaseContext(results);
        return {
          type: 'submit_prompt',
          content: `Based on the following relevant code from the codebase:\n\n${contextContent}\n\nUser question: ${query}`,
        };
      }

      case 'status': {
        const status = await indexService.getStatus();
        return {
          type: 'message',
          messageType: 'info',
          content: formatIndexStatus(status),
        };
      }

      case 'build': {
        await indexService.rebuild();
        return {
          type: 'message',
          messageType: 'info',
          content:
            'ğŸ”„ Index rebuild started in background. Use /codebase status to check progress.',
        };
      }

      case 'pause': {
        await indexService.pause();
        return {
          type: 'message',
          messageType: 'info',
          content: 'â¸ï¸ Index building paused.',
        };
      }

      case 'resume': {
        await indexService.resume();
        return {
          type: 'message',
          messageType: 'info',
          content: 'â–¶ï¸ Index building resumed.',
        };
      }

      case 'disable': {
        await indexService.disable();
        return {
          type: 'message',
          messageType: 'info',
          content: 'ğŸš« Codebase indexing disabled.',
        };
      }

      case 'enable': {
        await indexService.enable();
        return {
          type: 'message',
          messageType: 'info',
          content: 'âœ… Codebase indexing enabled.',
        };
      }

      default:
        return {
          type: 'message',
          messageType: 'error',
          content: `Unknown subcommand: ${subCommand}. Available: query, status, build, pause, resume, disable, enable`,
        };
    }
  },

  async completion(context, args) {
    const subCommands = [
      'query',
      'status',
      'build',
      'pause',
      'resume',
      'disable',
      'enable',
    ];
    if (args.length <= 1) {
      return subCommands.filter((cmd) => cmd.startsWith(args[0] || ''));
    }
    return [];
  },
};

function formatIndexStatus(status: IndexingProgress): string {
  const statusIcons: Record<string, string> = {
    idle: 'ğŸ’¤',
    scanning: 'ğŸ”',
    chunking: 'âœ‚ï¸',
    embedding: 'ğŸ§ ',
    storing: 'ğŸ’¾',
    done: 'âœ…',
    paused: 'â¸ï¸',
    error: 'âŒ',
  };

  const lines = [
    `${statusIcons[status.status]} Codebase Index Status: ${status.status.toUpperCase()}`,
    `â”œâ”€ Files: ${status.chunkedFiles} / ${status.totalFiles} processed`,
    `â”œâ”€ Chunks: ${status.embeddedChunks} / ${status.totalChunks} embedded`,
    `â”œâ”€ Progress: ${status.overallProgress}%`,
  ];

  if (status.estimatedTimeRemaining) {
    lines.push(
      `â””â”€ ETA: ~${Math.ceil(status.estimatedTimeRemaining / 60)} minutes`,
    );
  }

  if (status.error) {
    lines.push(`â””â”€ Error: ${status.error}`);
  }

  return lines.join('\n');
}
```

### 3.5 çŸ¥è¯†å›¾è°±ï¼ˆä¾èµ–å›¾ï¼‰

ä¸ºäº†è§£å†³ **FP7ï¼ˆä¸å®Œæ•´ï¼‰** é—®é¢˜â€”â€”å³è·¨æ–‡ä»¶ä¾èµ–è¿½è¸ªï¼Œæˆ‘ä»¬å¼•å…¥çŸ¥è¯†å›¾è°±å±‚ï¼ŒåŸºäº AST è‡ªåŠ¨æå–ä»£ç å®ä½“ä¸å…³ç³»ï¼Œå½¢æˆå…¨å±€ä¾èµ–å›¾ã€‚

#### 3.5.1 å›¾æ•°æ®æ¨¡å‹

```
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚                          å®ä½“èŠ‚ç‚¹ (Nodes)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Module  â”‚   â”‚   Class  â”‚   â”‚ Function â”‚   â”‚ Variable â”‚       â”‚
â”‚  â”‚  (æ–‡ä»¶)   â”‚   â”‚  (ç±»)    â”‚   â”‚  (å‡½æ•°)   â”‚   â”‚  (å˜é‡)   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚              â”‚              â”‚                              â”‚
â”‚       â”‚              â”‚              â”‚                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                          å…³ç³»è¾¹ (Edges)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  IMPORTS   : Module â”€â”€â”€â”€â”€â–¶ Module    (å¯¼å…¥å…³ç³»)                       â”‚
â”‚  EXPORTS   : Module â”€â”€â”€â”€â”€â–¶ Function  (å¯¼å‡ºå…³ç³»)                       â”‚
â”‚  CONTAINS  : Module â”€â”€â”€â”€â”€â–¶ Class     (åŒ…å«å…³ç³»)                       â”‚
â”‚  CALLS     : Function â”€â”€â”€â–¶ Function  (è°ƒç”¨å…³ç³»)                       â”‚
â”‚  EXTENDS   : Class â”€â”€â”€â”€â”€â”€â–¶ Class     (ç»§æ‰¿å…³ç³»)                       â”‚
â”‚  IMPLEMENTS: Class â”€â”€â”€â”€â”€â”€â–¶ Interface (å®ç°å…³ç³»)                       â”‚
â”‚  USES      : Function â”€â”€â”€â–¶ Variable  (ä½¿ç”¨å…³ç³»)                       â”‚
â”‚  DEFINES   : Module â”€â”€â”€â”€â”€â–¶ Variable  (å®šä¹‰å…³ç³»)                       â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å®ä½“ç±»å‹å®šä¹‰**ï¼š

```typescript
// packages/core/src/indexing/types.ts

// å›¾è°±å®ä½“ç±»å‹
type EntityType =
  | 'module'
  | 'class'
  | 'function'
  | 'method'
  | 'interface'
  | 'variable'
  | 'type';

// å…³ç³»ç±»å‹
type RelationType =
  | 'IMPORTS' // æ¨¡å—å¯¼å…¥
  | 'EXPORTS' // æ¨¡å—å¯¼å‡º
  | 'CONTAINS' // åŒ…å«ï¼ˆæ¨¡å—åŒ…å«ç±»/å‡½æ•°ï¼Œç±»åŒ…å«æ–¹æ³•ï¼‰
  | 'CALLS' // å‡½æ•°è°ƒç”¨
  | 'EXTENDS' // ç±»ç»§æ‰¿
  | 'IMPLEMENTS' // æ¥å£å®ç°
  | 'USES' // å˜é‡/ç±»å‹ä½¿ç”¨
  | 'DEFINES'; // å®šä¹‰

// å›¾è°±å®ä½“
interface GraphEntity {
  id: string; // å”¯ä¸€æ ‡è¯†: `${filePath}#${name}`
  name: string; // å®ä½“åç§°
  type: EntityType; // å®ä½“ç±»å‹
  filePath: string; // æ‰€åœ¨æ–‡ä»¶
  startLine: number; // èµ·å§‹è¡Œ
  endLine: number; // ç»“æŸè¡Œ
  signature?: string; // å‡½æ•°ç­¾å / ç±»å®šä¹‰
  docstring?: string; // æ–‡æ¡£æ³¨é‡Š
  chunkId?: string; // å…³è”çš„ chunk ID
}

// å›¾è°±å…³ç³»
interface GraphRelation {
  sourceId: string; // æºå®ä½“ ID
  targetId: string; // ç›®æ ‡å®ä½“ ID
  type: RelationType; // å…³ç³»ç±»å‹
  metadata?: {
    // å…³ç³»å…ƒæ•°æ®
    line?: number; // å…³ç³»å‘ç”Ÿçš„è¡Œå·
    alias?: string; // å¯¼å…¥åˆ«å
  };
}

// å›¾éå†ç»“æœ
interface GraphSubgraph {
  entities: GraphEntity[];
  relations: GraphRelation[];
  seedIds: string[]; // ç§å­å®ä½“ ID
  depth: number; // éå†æ·±åº¦
}
```

#### 3.5.2 å®ä½“æå–ï¼ˆEntityExtractorï¼‰

åŸºäº AST éå†æå–ä»£ç å®ä½“ï¼Œå¤ç”¨å·²æœ‰çš„ Tree-sitter åŸºç¡€è®¾æ–½ï¼š

```typescript
// packages/core/src/indexing/entityExtractor.ts

import Parser from 'tree-sitter';
import TypeScript from 'tree-sitter-typescript';

/**
 * AST-based entity and relation extractor.
 * Extracts functions, classes, imports, and their relationships.
 */
export class EntityExtractor {
  private parser: Parser;

  constructor() {
    this.parser = new Parser();
  }

  /**
   * Extract entities and relations from a source file.
   */
  async extract(
    filePath: string,
    content: string,
    language: string,
  ): Promise<{
    entities: GraphEntity[];
    relations: GraphRelation[];
  }> {
    this.parser.setLanguage(this.getLanguage(language));
    const tree = this.parser.parse(content);

    const entities: GraphEntity[] = [];
    const relations: GraphRelation[] = [];

    // æ¨¡å—å®ä½“ï¼ˆæ–‡ä»¶æœ¬èº«ï¼‰
    const moduleId = filePath;
    entities.push({
      id: moduleId,
      name: path.basename(filePath),
      type: 'module',
      filePath,
      startLine: 1,
      endLine: content.split('\n').length,
    });

    // éå† AST
    this.traverse(tree.rootNode, (node) => {
      // æå– import è¯­å¥
      if (node.type === 'import_statement') {
        const importInfo = this.parseImport(node, filePath);
        if (importInfo) {
          relations.push({
            sourceId: moduleId,
            targetId: importInfo.targetModule,
            type: 'IMPORTS',
            metadata: { line: node.startPosition.row + 1 },
          });
        }
      }

      // æå–å‡½æ•°å®šä¹‰
      if (
        node.type === 'function_declaration' ||
        node.type === 'arrow_function'
      ) {
        const funcEntity = this.parseFunction(node, filePath);
        if (funcEntity) {
          entities.push(funcEntity);
          relations.push({
            sourceId: moduleId,
            targetId: funcEntity.id,
            type: 'CONTAINS',
          });

          // æå–å‡½æ•°å†…çš„è°ƒç”¨å…³ç³»
          this.extractCalls(node, funcEntity.id, relations);
        }
      }

      // æå–ç±»å®šä¹‰
      if (node.type === 'class_declaration') {
        const classEntity = this.parseClass(node, filePath);
        if (classEntity) {
          entities.push(classEntity);
          relations.push({
            sourceId: moduleId,
            targetId: classEntity.id,
            type: 'CONTAINS',
          });

          // æå–ç»§æ‰¿å…³ç³»
          const extendsClause = node.childForFieldName('heritage');
          if (extendsClause) {
            const superClass = this.parseHeritage(extendsClause, filePath);
            if (superClass) {
              relations.push({
                sourceId: classEntity.id,
                targetId: superClass,
                type: 'EXTENDS',
              });
            }
          }

          // æå–æ–¹æ³•
          this.extractMethods(
            node,
            classEntity.id,
            filePath,
            entities,
            relations,
          );
        }
      }

      // æå– export è¯­å¥
      if (node.type === 'export_statement') {
        const exportedName = this.parseExport(node);
        if (exportedName) {
          relations.push({
            sourceId: moduleId,
            targetId: `${filePath}#${exportedName}`,
            type: 'EXPORTS',
          });
        }
      }
    });

    return { entities, relations };
  }

  private traverse(
    node: Parser.SyntaxNode,
    callback: (node: Parser.SyntaxNode) => void,
  ): void {
    callback(node);
    for (const child of node.children) {
      this.traverse(child, callback);
    }
  }

  private parseFunction(
    node: Parser.SyntaxNode,
    filePath: string,
  ): GraphEntity | null {
    const nameNode = node.childForFieldName('name');
    if (!nameNode) return null;

    const name = nameNode.text;
    return {
      id: `${filePath}#${name}`,
      name,
      type: 'function',
      filePath,
      startLine: node.startPosition.row + 1,
      endLine: node.endPosition.row + 1,
      signature: this.extractSignature(node),
    };
  }

  private parseClass(
    node: Parser.SyntaxNode,
    filePath: string,
  ): GraphEntity | null {
    const nameNode = node.childForFieldName('name');
    if (!nameNode) return null;

    const name = nameNode.text;
    return {
      id: `${filePath}#${name}`,
      name,
      type: 'class',
      filePath,
      startLine: node.startPosition.row + 1,
      endLine: node.endPosition.row + 1,
    };
  }

  private extractCalls(
    funcNode: Parser.SyntaxNode,
    funcId: string,
    relations: GraphRelation[],
  ): void {
    // éå†å‡½æ•°ä½“ï¼ŒæŸ¥æ‰¾è°ƒç”¨è¡¨è¾¾å¼
    this.traverse(funcNode, (node) => {
      if (node.type === 'call_expression') {
        const callee = node.childForFieldName('function');
        if (callee) {
          relations.push({
            sourceId: funcId,
            targetId: callee.text, // æ³¨æ„: éœ€è¦è§£æä¸ºå®Œæ•´ ID
            type: 'CALLS',
            metadata: { line: node.startPosition.row + 1 },
          });
        }
      }
    });
  }

  // ... å…¶ä»–è¾…åŠ©æ–¹æ³•
}
```

#### 3.5.3 å›¾éå†ä¸å­å›¾æå–

ä»ç§å­å—å‡ºå‘ï¼Œæ²¿è°ƒç”¨/ç»§æ‰¿/å¯¼å…¥å…³ç³»æ‰©å±•ï¼Œæå–æœ€å°å®Œå¤‡å­å›¾ï¼š

```typescript
// packages/core/src/indexing/graphTraverser.ts

import { GraphStore } from './stores/graphStore';

/**
 * Graph traversal service for extracting relevant subgraphs.
 * Uses multi-hop BFS to find related entities from seed chunks.
 */
export class GraphTraverser {
  constructor(private graphStore: GraphStore) {}

  /**
   * Extract a minimal complete subgraph starting from seed entities.
   *
   * @param seedChunkIds - Chunk IDs from initial retrieval results
   * @param options - Traversal options
   * @returns Subgraph containing related entities and relations
   */
  async extractSubgraph(
    seedChunkIds: string[],
    options: {
      maxDepth?: number; // æœ€å¤§è·³æ•°ï¼Œé»˜è®¤ 2
      maxNodes?: number; // æœ€å¤§èŠ‚ç‚¹æ•°ï¼Œé»˜è®¤ 50
      relationTypes?: RelationType[]; // è¦éå†çš„å…³ç³»ç±»å‹
      direction?: 'outgoing' | 'incoming' | 'both'; // éå†æ–¹å‘
    } = {},
  ): Promise<GraphSubgraph> {
    const {
      maxDepth = 2,
      maxNodes = 50,
      relationTypes = ['CALLS', 'IMPORTS', 'EXTENDS', 'IMPLEMENTS'],
      direction = 'both',
    } = options;

    // 1. ä» chunk ID æŸ¥æ‰¾å¯¹åº”çš„å®ä½“ ID
    const seedEntityIds =
      await this.graphStore.getEntitiesByChunkIds(seedChunkIds);

    if (seedEntityIds.length === 0) {
      return { entities: [], relations: [], seedIds: [], depth: 0 };
    }

    // 2. Cypher æŸ¥è¯¢ï¼šå¤šè·³éå†
    const query = `
      MATCH path = (seed:Entity)-[r:${relationTypes.join('|')}*1..${maxDepth}]-(related:Entity)
      WHERE seed.id IN $seedIds
      RETURN DISTINCT 
        nodes(path) as pathNodes,
        relationships(path) as pathRels
      LIMIT ${maxNodes * 2}
    `;

    const result = await this.graphStore.query(query, {
      seedIds: seedEntityIds,
    });

    // 3. å»é‡å¹¶æ„å»ºå­å›¾
    const entityMap = new Map<string, GraphEntity>();
    const relationSet = new Set<string>();
    const relations: GraphRelation[] = [];

    for (const row of result) {
      for (const node of row.pathNodes) {
        if (!entityMap.has(node.id) && entityMap.size < maxNodes) {
          entityMap.set(node.id, node);
        }
      }
      for (const rel of row.pathRels) {
        const relKey = `${rel.sourceId}-${rel.type}->${rel.targetId}`;
        if (!relationSet.has(relKey)) {
          relationSet.add(relKey);
          relations.push(rel);
        }
      }
    }

    return {
      entities: Array.from(entityMap.values()),
      relations,
      seedIds: seedEntityIds,
      depth: maxDepth,
    };
  }

  /**
   * Find shortest path between two entities.
   */
  async findPath(
    sourceId: string,
    targetId: string,
    maxDepth: number = 5,
  ): Promise<GraphRelation[]> {
    const query = `
      MATCH path = shortestPath((a:Entity {id: $source})-[*1..${maxDepth}]-(b:Entity {id: $target}))
      RETURN relationships(path) as rels
    `;
    const result = await this.graphStore.query(query, {
      source: sourceId,
      target: targetId,
    });
    return result[0]?.rels || [];
  }
}
```

#### 3.5.4 å¢å¼ºçš„æ£€ç´¢æµç¨‹

å°†å›¾è°±é›†æˆåˆ°ç°æœ‰çš„æ£€ç´¢æµç¨‹ä¸­ï¼š

```
æ£€ç´¢å¢å¼ºæµç¨‹:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query   â”‚â”€â”€â”€â”€â–¶â”‚  Hybrid Search  â”‚â”€â”€â”€â”€â–¶â”‚  Seed Chunks    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  (BM25+Vector)  â”‚     â”‚  (Top-K ç»“æœ)    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Graph Traverser â”‚â—€â”€â”€â”€â”€â”‚ Chunk â†’ Entity  â”‚
                  â”‚ (Multi-hop BFS) â”‚     â”‚   ID Mapping    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Minimal Subgraphâ”‚
                  â”‚ (å®ä½“ + å…³ç³»)    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Context Builder                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Text View              â”‚   Graph View           â”‚
â”‚  (ä»£ç å—å†…å®¹)           â”‚   (ä¾èµ–å…³ç³»å›¾)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ›´æ–° RetrievalService**ï¼š

````typescript
// packages/core/src/indexing/retrievalService.ts (å¢å¼ºç‰ˆ)

export class RetrievalService {
  constructor(
    private vectorStore: VectorStore,
    private metadataStore: MetadataStore,
    private graphStore: GraphStore, // æ–°å¢
    private graphTraverser: GraphTraverser, // æ–°å¢
    private llmClient: BaseLlmClient,
  ) {}

  async retrieve(
    query: string,
    options: RetrieveOptions = {},
  ): Promise<RetrievalResult> {
    const {
      topK = 10,
      enableGraph = true, // æ˜¯å¦å¯ç”¨å›¾æ‰©å±•
      graphDepth = 2, // å›¾éå†æ·±åº¦
      maxGraphNodes = 30, // æœ€å¤§å›¾èŠ‚ç‚¹æ•°
      maxTokens = 8000,
    } = options;

    // 1. æ··åˆæ£€ç´¢è·å–ç§å­å—
    const seedChunks = await this.hybridSearch(query, topK);

    // 2. å›¾æ‰©å±•ï¼ˆå¯é€‰ï¼‰
    let subgraph: GraphSubgraph | null = null;
    if (enableGraph && seedChunks.length > 0) {
      const seedChunkIds = seedChunks.map((c) => c.id);
      subgraph = await this.graphTraverser.extractSubgraph(seedChunkIds, {
        maxDepth: graphDepth,
        maxNodes: maxGraphNodes,
        relationTypes: ['CALLS', 'IMPORTS', 'EXTENDS', 'IMPLEMENTS'],
      });
    }

    // 3. æ„å»ºç»“æœ
    return {
      chunks: seedChunks,
      subgraph,
      textView: this.buildTextView(seedChunks, maxTokens),
      graphView: subgraph ? this.buildGraphView(subgraph) : null,
    };
  }

  /**
   * Build text view: code content with file paths.
   */
  private buildTextView(chunks: ScoredChunk[], maxTokens: number): string {
    const lines: string[] = ['## Relevant Code\n'];
    let tokenCount = 0;

    for (const chunk of chunks) {
      const chunkTokens = this.estimateTokens(chunk.content);
      if (tokenCount + chunkTokens > maxTokens) break;

      lines.push(`### ${chunk.filePath}:${chunk.startLine}-${chunk.endLine}`);
      lines.push('```' + chunk.language);
      lines.push(chunk.content);
      lines.push('```\n');
      tokenCount += chunkTokens;
    }

    return lines.join('\n');
  }

  /**
   * Build graph view: dependency relationships in Mermaid format.
   */
  private buildGraphView(subgraph: GraphSubgraph): string {
    const lines: string[] = ['## Dependency Graph\n', '```mermaid', 'graph LR'];

    // æ·»åŠ èŠ‚ç‚¹
    for (const entity of subgraph.entities) {
      const label = `${entity.type}:${entity.name}`;
      const isSeed = subgraph.seedIds.includes(entity.id);
      const style = isSeed ? ':::seed' : '';
      lines.push(`  ${this.sanitizeId(entity.id)}["${label}"]${style}`);
    }

    // æ·»åŠ è¾¹
    for (const rel of subgraph.relations) {
      const arrow = this.getArrowStyle(rel.type);
      lines.push(
        `  ${this.sanitizeId(rel.sourceId)} ${arrow} ${this.sanitizeId(rel.targetId)}`,
      );
    }

    lines.push('  classDef seed fill:#f9f,stroke:#333');
    lines.push('```');

    return lines.join('\n');
  }

  private getArrowStyle(relType: RelationType): string {
    const arrows: Record<RelationType, string> = {
      CALLS: '-->|calls|',
      IMPORTS: '-.->|imports|',
      EXTENDS: '==>|extends|',
      IMPLEMENTS: '-.->|implements|',
      CONTAINS: '-->|contains|',
      EXPORTS: '-->|exports|',
      USES: '-->|uses|',
      DEFINES: '-->|defines|',
    };
    return arrows[relType] || '-->';
  }
}

// æ›´æ–°çš„è¿”å›ç±»å‹
interface RetrievalResult {
  chunks: ScoredChunk[];
  subgraph: GraphSubgraph | null;
  textView: string; // ä»£ç å†…å®¹è§†å›¾
  graphView: string | null; // Mermaid å›¾è°±è§†å›¾
}
````

#### 3.5.5 è¾“å‡ºç¤ºä¾‹

æ£€ç´¢æŸ¥è¯¢ `"ç”¨æˆ·è®¤è¯å¦‚ä½•å®ç°"` åçš„è¾“å‡ºï¼š

````markdown
## Relevant Code

### src/services/authService.ts:15-45

```typescript
export class AuthService {
  constructor(
    private userRepo: UserRepository,
    private jwt: JwtService,
  ) {}

  async login(email: string, password: string): Promise<AuthResult> {
    const user = await this.userRepo.findByEmail(email);
    if (!user || !(await this.verifyPassword(password, user.passwordHash))) {
      throw new UnauthorizedError('Invalid credentials');
    }
    return { token: this.jwt.sign({ userId: user.id }) };
  }
}
```
````

### src/middleware/authMiddleware.ts:8-25

```typescript
export function authMiddleware(
  req: Request,
  res: Response,
  next: NextFunction,
) {
  const token = req.headers.authorization?.split(' ')[1];
  if (!token) return res.status(401).json({ error: 'No token' });
  // ...
}
```

## Dependency Graph

```mermaid
graph LR
  AuthService["class:AuthService"]:::seed
  UserRepository["class:UserRepository"]
  JwtService["class:JwtService"]
  authMiddleware["function:authMiddleware"]:::seed
  login["method:login"]

  AuthService -->|contains| login
  AuthService -.->|imports| UserRepository
  AuthService -.->|imports| JwtService
  authMiddleware -->|calls| JwtService

  classDef seed fill:#f9f,stroke:#333
```

````

---

## 4. æŠ€æœ¯é€‰å‹

### 4.1 ä»£ç åˆ†å—ç­–ç•¥

#### 4.1.1 åŸºäº AST çš„æ™ºèƒ½åˆ†å— (cAST æ–¹æ³•)

æ ¹æ®ä¸šç•Œæœ€ä½³å®è·µï¼ˆå‚è€ƒ DeepWiki RAG é¢„æ£€ç´¢é˜¶æ®µï¼‰ï¼Œæˆ‘ä»¬é‡‡ç”¨**ç»“æ„æ„ŸçŸ¥çš„ä»£ç åˆ†å—**ï¼Œæ ¸å¿ƒåŸåˆ™ï¼š

- ä¿è¯å‡½æ•°ã€ç±»ã€æ–¹æ³•ç­‰å®Œæ•´å•å…ƒçš„è¯­æ³•å’Œè¯­ä¹‰è¿ç»­æ€§
- é¿å…ä¼ ç»Ÿè¡Œæ•°åˆ†å—ç ´åé€»è¾‘è¾¹ç•Œ
- ä½¿ç”¨ AST é€’å½’åˆ†å‰²ä¸åˆå¹¶ï¼Œæ—¢ä¿æŒå®Œæ•´æ€§åˆé¿å…è¿‡åº¦ç¢ç‰‡åŒ–

```typescript
// packages/core/src/indexing/chunkingService.ts

interface Chunk {
  id: string; // UUID
  filepath: string;
  content: string;
  startLine: number;
  endLine: number;
  index: number; // chunk åœ¨æ–‡ä»¶ä¸­çš„åºå·
  contentHash: string; // SHA-256 of content
  type: ChunkType; // è¯­ä¹‰ç±»å‹
  metadata: ChunkMetadata; // å…ƒæ•°æ®å¢å¼º
}

type ChunkType =
  | 'function'
  | 'class'
  | 'method'
  | 'interface'
  | 'module'
  | 'import'
  | 'config'
  | 'block';

interface ChunkMetadata {
  language: string;
  functionName?: string;
  className?: string;
  imports?: string[]; // ä¾èµ–çš„æ¨¡å—
  exports?: string[]; // å¯¼å‡ºçš„ç¬¦å·
  signature?: string; // å‡½æ•°ç­¾å
}

// åˆ†å—é…ç½®
const CHUNKING_CONFIG = {
  maxChunkTokens: 512, // æœ€å¤§ token æ•°
  minChunkTokens: 100, // æœ€å° token æ•°ï¼ˆå¤ªå°åˆå¹¶ï¼‰
  overlapTokens: 50, // é‡å  token æ•°
  maxChunkLines: 100, // æœ€å¤§è¡Œæ•°ï¼ˆç¡¬é™åˆ¶ï¼‰
};
````

#### 4.1.2 åˆ†å—ç®—æ³•

```typescript
// packages/core/src/indexing/chunkingService.ts

class ChunkingService {
  async chunkFile(filepath: string, content: string): Promise<Chunk[]> {
    const language = detectLanguage(filepath);

    // å°è¯• AST åˆ†å—
    if (this.supportedLanguages.has(language)) {
      try {
        return await this.astChunk(filepath, content, language);
      } catch (error) {
        // AST è§£æå¤±è´¥ï¼Œfallback åˆ°è¡Œåˆ†å—
        console.warn(
          `AST parsing failed for ${filepath}, falling back to line-based chunking`,
        );
      }
    }

    // Fallback: æ»‘åŠ¨çª—å£åˆ†å—
    return this.lineBasedChunk(filepath, content, language);
  }

  private async astChunk(
    filepath: string,
    content: string,
    language: string,
  ): Promise<Chunk[]> {
    const parser = await getTreeSitterParser(language);
    const tree = parser.parse(content);

    const chunks: Chunk[] = [];
    const nodeTypes = this.getChunkableNodeTypes(language);

    // éå† ASTï¼Œæå–å¯åˆ†å—èŠ‚ç‚¹
    this.walkTree(tree.rootNode, (node) => {
      if (nodeTypes.includes(node.type)) {
        const nodeContent = content.slice(node.startIndex, node.endIndex);
        const tokenCount = this.countTokens(nodeContent);

        if (tokenCount <= CHUNKING_CONFIG.maxChunkTokens) {
          // èŠ‚ç‚¹å¤§å°åˆé€‚ï¼Œç›´æ¥ä½œä¸º chunk
          chunks.push(this.createChunk(filepath, node, nodeContent, language));
        } else {
          // èŠ‚ç‚¹å¤ªå¤§ï¼Œé€’å½’åˆ†å‰²å­èŠ‚ç‚¹
          const subChunks = this.splitLargeNode(
            filepath,
            node,
            content,
            language,
          );
          chunks.push(...subChunks);
        }
      }
    });

    // åˆå¹¶è¿‡å°çš„ç›¸é‚» chunks
    return this.mergeSmallChunks(chunks);
  }

  private getChunkableNodeTypes(language: string): string[] {
    const typeMap: Record<string, string[]> = {
      typescript: [
        'function_declaration',
        'method_definition',
        'class_declaration',
        'interface_declaration',
        'type_alias_declaration',
        'export_statement',
      ],
      javascript: [
        'function_declaration',
        'method_definition',
        'class_declaration',
        'export_statement',
      ],
      python: [
        'function_definition',
        'class_definition',
        'decorated_definition',
      ],
      rust: [
        'function_item',
        'impl_item',
        'struct_item',
        'enum_item',
        'mod_item',
      ],
      go: ['function_declaration', 'method_declaration', 'type_declaration'],
      java: [
        'method_declaration',
        'class_declaration',
        'interface_declaration',
      ],
    };
    return typeMap[language] || [];
  }

  private lineBasedChunk(
    filepath: string,
    content: string,
    language: string,
  ): Chunk[] {
    const lines = content.split('\n');
    const chunks: Chunk[] = [];
    let currentChunk: string[] = [];
    let startLine = 1;
    let tokenCount = 0;

    for (let i = 0; i < lines.length; i++) {
      const line = lines[i];
      const lineTokens = this.countTokens(line);

      if (
        tokenCount + lineTokens > CHUNKING_CONFIG.maxChunkTokens &&
        currentChunk.length > 0
      ) {
        // å½“å‰ chunk å·²æ»¡ï¼Œä¿å­˜å¹¶å¼€å§‹æ–° chunk
        chunks.push(
          this.createLineChunk(
            filepath,
            currentChunk.join('\n'),
            startLine,
            i,
            language,
            chunks.length,
          ),
        );

        // ä¿ç•™ overlap
        const overlapLines = this.getOverlapLines(
          currentChunk,
          CHUNKING_CONFIG.overlapTokens,
        );
        currentChunk = [...overlapLines, line];
        startLine = i + 1 - overlapLines.length;
        tokenCount = this.countTokens(currentChunk.join('\n'));
      } else {
        currentChunk.push(line);
        tokenCount += lineTokens;
      }
    }

    // ä¿å­˜æœ€åä¸€ä¸ª chunk
    if (currentChunk.length > 0) {
      chunks.push(
        this.createLineChunk(
          filepath,
          currentChunk.join('\n'),
          startLine,
          lines.length,
          language,
          chunks.length,
        ),
      );
    }

    return chunks;
  }
}
```

#### 4.1.3 æ”¯æŒçš„è¯­è¨€

| è¯­è¨€       | Tree-sitter Parser       | åˆ†å—èŠ‚ç‚¹ç±»å‹                             |
| ---------- | ------------------------ | ---------------------------------------- |
| TypeScript | `tree-sitter-typescript` | function, class, interface, type, export |
| JavaScript | `tree-sitter-javascript` | function, class, export                  |
| Python     | `tree-sitter-python`     | function_definition, class_definition    |
| Rust       | `tree-sitter-rust`       | function_item, impl_item, struct_item    |
| Go         | `tree-sitter-go`         | function_declaration, type_declaration   |
| Java       | `tree-sitter-java`       | method_declaration, class_declaration    |
| å…¶ä»–       | N/A                      | åŸºäºè¡Œçš„æ»‘åŠ¨çª—å£                         |

### 4.2 å‘é‡æ•°æ®åº“: Zvec

#### 4.2.1 ä¸ºä»€ä¹ˆé€‰æ‹© Zvec

1. **é«˜æ€§èƒ½**ï¼šRust å®ç°ï¼ŒHNSW ç´¢å¼•ï¼ŒæŸ¥è¯¢å»¶è¿Ÿ <10ms
2. **In-process**ï¼šæ— éœ€å¤–éƒ¨æœåŠ¡ï¼Œé€šè¿‡ NAPI ç›´æ¥è°ƒç”¨
3. **è½»é‡çº§**ï¼šå•æ–‡ä»¶å­˜å‚¨ï¼Œæ— é¢å¤–ä¾èµ–
4. **åŠŸèƒ½å®Œæ•´**ï¼šæ”¯æŒ Dense/Sparse å‘é‡ã€æ ‡é‡å­—æ®µè¿‡æ»¤ã€CRUD æ“ä½œ

#### 4.2.2 Zvec é›†æˆå®ç°

```typescript
// packages/core/src/indexing/stores/vectorStore.ts

import {
  ZVecCollection,
  ZVecCollectionSchema,
  ZVecCreateAndOpen,
  ZVecOpen,
  ZVecDataType,
  ZVecDoc,
  ZVecFieldSchema,
  ZVecIndexType,
  ZVecMetricType,
  ZVecVectorSchema,
  ZVecInitialize,
  ZVecInitOptions,
  ZVecLogLevel,
  ZVecLogType,
} from 'zvec';

class VectorStore {
  private collection: ZVecCollection | null = null;
  private readonly collectionPath: string;

  constructor(projectHash: string) {
    this.collectionPath = path.join(
      getGlobalQwenPath(),
      'index',
      projectHash,
      'vectors',
    );
  }

  async initialize(): Promise<void> {
    // å…¨å±€åˆå§‹åŒ–ï¼ˆåªéœ€ä¸€æ¬¡ï¼‰
    ZVecInitialize({
      logType: ZVecLogType.CONSOLE,
      logLevel: ZVecLogLevel.WARN,
    });

    // å®šä¹‰ schema
    const contentEmbedding: ZVecVectorSchema = {
      name: 'content_embedding',
      dataType: ZVecDataType.VECTOR_FP32,
      dimension: 1024, // text-embedding-v4 ç»´åº¦
      indexParams: {
        indexType: ZVecIndexType.HNSW,
        metricType: ZVecMetricType.COSINE,
      },
    };

    const chunkId: ZVecFieldSchema = {
      name: 'chunk_id',
      dataType: ZVecDataType.STRING,
      nullable: false,
    };

    const filePath: ZVecFieldSchema = {
      name: 'file_path',
      dataType: ZVecDataType.STRING,
      nullable: false,
      indexParams: {
        indexType: ZVecIndexType.INVERT, // æ”¯æŒæŒ‰æ–‡ä»¶è·¯å¾„è¿‡æ»¤
      },
    };

    const chunkContent: ZVecFieldSchema = {
      name: 'chunk_content',
      dataType: ZVecDataType.STRING,
      nullable: false,
    };

    const schema = new ZVecCollectionSchema({
      name: 'codebase_vectors',
      vectors: [contentEmbedding],
      fields: [chunkId, filePath, chunkContent],
    });

    // åˆ›å»ºæˆ–æ‰“å¼€ collection
    try {
      if (await this.collectionExists()) {
        this.collection = ZVecOpen(this.collectionPath);
      } else {
        this.collection = ZVecCreateAndOpen(this.collectionPath, schema);
      }
    } catch (error) {
      throw new Error(`Failed to initialize vector store: ${error}`);
    }
  }

  // æ‰¹é‡æ’å…¥ (100 docs/batch)
  async insertBatch(
    docs: Array<{ chunk: Chunk; embedding: number[] }>,
  ): Promise<void> {
    const BATCH_SIZE = 100;

    for (let i = 0; i < docs.length; i += BATCH_SIZE) {
      const batch = docs.slice(i, i + BATCH_SIZE);
      const zvecDocs: ZVecDoc[] = batch.map(({ chunk, embedding }) => ({
        id: chunk.id,
        vectors: {
          content_embedding: new Float32Array(embedding),
        },
        fields: {
          chunk_id: chunk.id,
          file_path: chunk.filepath,
          chunk_content: chunk.content,
        },
      }));

      const result = this.collection!.insert(zvecDocs);
      if (!result.ok) {
        throw new Error(`Batch insert failed at index ${i}`);
      }
    }
  }

  // å‘é‡æŸ¥è¯¢
  async query(
    queryVector: number[],
    topK: number,
    filter?: string,
  ): Promise<VectorSearchResult[]> {
    const results = this.collection!.query({
      fieldName: 'content_embedding',
      topk: topK,
      vector: new Float32Array(queryVector),
      ...(filter && { filter }),
    });

    return results.map((doc, rank) => ({
      chunkId: doc.fields.chunk_id as string,
      filePath: doc.fields.file_path as string,
      content: doc.fields.chunk_content as string,
      score: doc.score || 0,
      rank: rank + 1,
    }));
  }

  // æŒ‰æ–‡ä»¶è·¯å¾„åˆ é™¤
  async deleteByFilePath(filePath: string): Promise<void> {
    // Zvec ç›®å‰ä¸ç›´æ¥æ”¯æŒæŒ‰ filter åˆ é™¤ï¼Œéœ€è¦å…ˆæŸ¥è¯¢å†åˆ é™¤
    const docs = this.collection!.query({
      topk: 10000,
      filter: `file_path = '${filePath}'`,
    });

    for (const doc of docs) {
      this.collection!.delete(doc.id);
    }
  }

  // ä¼˜åŒ–ç´¢å¼•ï¼ˆæ„å»ºå®Œæˆåè°ƒç”¨ï¼‰
  optimize(): void {
    this.collection!.optimize();
  }

  // é”€æ¯
  destroy(): void {
    if (this.collection) {
      this.collection.destroy();
      this.collection = null;
    }
  }
}
```

### 4.3 å…³ç³»å‹å­˜å‚¨: SQLite

ä½¿ç”¨ **better-sqlite3** å­˜å‚¨å…ƒæ•°æ®å’Œ FTS ç´¢å¼•ï¼š

```typescript
// packages/core/src/indexing/stores/metadataStore.ts

import Database from 'better-sqlite3';

const SCHEMA = `
-- æ–‡ä»¶å…ƒæ•°æ®
CREATE TABLE IF NOT EXISTS file_meta (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    path TEXT NOT NULL UNIQUE,
    content_hash TEXT NOT NULL,
    last_modified INTEGER NOT NULL,
    size INTEGER NOT NULL,
    language TEXT,
    indexed_at INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX IF NOT EXISTS idx_file_meta_path ON file_meta(path);
CREATE INDEX IF NOT EXISTS idx_file_meta_hash ON file_meta(content_hash);

-- ä»£ç å—
CREATE TABLE IF NOT EXISTS chunks (
    id TEXT PRIMARY KEY,
    file_id INTEGER NOT NULL,
    file_path TEXT NOT NULL,
    content TEXT NOT NULL,
    start_line INTEGER NOT NULL,
    end_line INTEGER NOT NULL,
    chunk_index INTEGER NOT NULL,
    content_hash TEXT NOT NULL,
    chunk_type TEXT,
    metadata_json TEXT,
    FOREIGN KEY (file_id) REFERENCES file_meta(id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_chunks_file_id ON chunks(file_id);
CREATE INDEX IF NOT EXISTS idx_chunks_file_path ON chunks(file_path);
CREATE INDEX IF NOT EXISTS idx_chunks_hash ON chunks(content_hash);

-- Embedding ç¼“å­˜ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
CREATE TABLE IF NOT EXISTS embedding_cache (
    content_hash TEXT PRIMARY KEY,
    embedding BLOB NOT NULL,
    created_at INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

-- FTS5 å…¨æ–‡æœç´¢
CREATE VIRTUAL TABLE IF NOT EXISTS fts_chunks USING fts5(
    file_path,
    content,
    content='chunks',
    content_rowid='rowid',
    tokenize='trigram'
);

-- FTS åŒæ­¥è§¦å‘å™¨
CREATE TRIGGER IF NOT EXISTS chunks_ai AFTER INSERT ON chunks BEGIN
    INSERT INTO fts_chunks(rowid, file_path, content) VALUES (new.rowid, new.file_path, new.content);
END;

CREATE TRIGGER IF NOT EXISTS chunks_ad AFTER DELETE ON chunks BEGIN
    INSERT INTO fts_chunks(fts_chunks, rowid, file_path, content) VALUES('delete', old.rowid, old.file_path, old.content);
END;

CREATE TRIGGER IF NOT EXISTS chunks_au AFTER UPDATE ON chunks BEGIN
    INSERT INTO fts_chunks(fts_chunks, rowid, file_path, content) VALUES('delete', old.rowid, old.file_path, old.content);
    INSERT INTO fts_chunks(rowid, file_path, content) VALUES (new.rowid, new.file_path, new.content);
END;

-- ç´¢å¼•çŠ¶æ€
CREATE TABLE IF NOT EXISTS index_status (
    id INTEGER PRIMARY KEY CHECK (id = 1),
    status TEXT NOT NULL DEFAULT 'idle',
    total_files INTEGER DEFAULT 0,
    indexed_files INTEGER DEFAULT 0,
    total_chunks INTEGER DEFAULT 0,
    current_branch TEXT,
    last_poll_at INTEGER,
    started_at INTEGER,
    completed_at INTEGER,
    error TEXT
);

INSERT OR IGNORE INTO index_status (id) VALUES (1);

-- æ–­ç‚¹ç»­ä¼ ï¼ˆæ”¯æŒå´©æºƒæ¢å¤ï¼‰
CREATE TABLE IF NOT EXISTS build_checkpoint (
    id INTEGER PRIMARY KEY CHECK (id = 1),
    phase TEXT,                    -- 'scanning' | 'chunking' | 'embedding' | 'storing'
    last_processed_path TEXT,      -- æœ€åæˆåŠŸå¤„ç†çš„æ–‡ä»¶è·¯å¾„
    pending_chunk_ids TEXT,        -- JSON array of chunk IDs pending embedding
    updated_at INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

INSERT OR IGNORE INTO build_checkpoint (id, phase) VALUES (1, NULL);
`;

/**
 * SQLite-based metadata storage for codebase indexing.
 * Handles file metadata, chunks, FTS index, and embedding cache.
 */
class MetadataStore {
  private db: Database.Database;

  constructor(projectHash: string) {
    const dbPath = path.join(
      getGlobalQwenPath(),
      'index',
      projectHash,
      'metadata.db',
    );
    ensureDir(path.dirname(dbPath));

    this.db = new Database(dbPath);
    this.db.pragma('journal_mode = WAL');
    this.db.pragma('synchronous = NORMAL');
    this.db.pragma('foreign_keys = ON');
    this.db.exec(SCHEMA);
  }

  /**
   * Inserts or updates file metadata in a single transaction.
   * @param files Array of file metadata to insert.
   */
  insertFileMeta(files: FileMetadata[]): void {
    const insert = this.db.prepare(`
      INSERT OR REPLACE INTO file_meta (path, content_hash, last_modified, size, language)
      VALUES (?, ?, ?, ?, ?)
    `);

    const transaction = this.db.transaction((files: FileMetadata[]) => {
      for (const file of files) {
        insert.run(
          file.path,
          file.contentHash,
          file.lastModified,
          file.size,
          file.language,
        );
      }
    });

    transaction(files);
  }

  /**
   * Inserts chunks in batches of 500 for optimal performance.
   * @param chunks Array of chunks to insert.
   */
  insertChunks(chunks: Chunk[]): void {
    const insert = this.db.prepare(`
      INSERT INTO chunks (id, file_id, file_path, content, start_line, end_line, chunk_index, content_hash, chunk_type, metadata_json)
      SELECT ?, id, ?, ?, ?, ?, ?, ?, ?, ?
      FROM file_meta WHERE path = ?
    `);

    const transaction = this.db.transaction((chunks: Chunk[]) => {
      for (const chunk of chunks) {
        insert.run(
          chunk.id,
          chunk.filepath,
          chunk.content,
          chunk.startLine,
          chunk.endLine,
          chunk.index,
          chunk.contentHash,
          chunk.type,
          JSON.stringify(chunk.metadata),
          chunk.filepath,
        );
      }
    });

    // åˆ†æ‰¹æ‰§è¡Œï¼Œæ¯æ‰¹ 500
    const BATCH_SIZE = 500;
    for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
      transaction(chunks.slice(i, i + BATCH_SIZE));
    }
  }

  // BM25 å…¨æ–‡æœç´¢
  searchFTS(
    query: string,
    limit: number,
  ): Array<{
    chunkId: string;
    filePath: string;
    content: string;
    score: number;
  }> {
    return this.db
      .prepare(
        `
      SELECT 
        c.id as chunkId,
        c.file_path as filePath,
        c.content,
        bm25(fts_chunks, 1.0, 0.75) as score
      FROM fts_chunks
      JOIN chunks c ON fts_chunks.rowid = c.rowid
      WHERE fts_chunks MATCH ?
      ORDER BY score
      LIMIT ?
    `,
      )
      .all(query, limit) as any[];
  }

  // è·å– embedding ç¼“å­˜
  getEmbeddingCache(contentHash: string): number[] | null {
    const row = this.db
      .prepare('SELECT embedding FROM embedding_cache WHERE content_hash = ?')
      .get(contentHash) as { embedding: Buffer } | undefined;
    if (row) {
      return Array.from(new Float32Array(row.embedding.buffer));
    }
    return null;
  }

  // å­˜å‚¨ embedding ç¼“å­˜
  setEmbeddingCache(contentHash: string, embedding: number[]): void {
    const buffer = Buffer.from(new Float32Array(embedding).buffer);
    this.db
      .prepare(
        'INSERT OR REPLACE INTO embedding_cache (content_hash, embedding) VALUES (?, ?)',
      )
      .run(contentHash, buffer);
  }

  close(): void {
    this.db.close();
  }
}
```

### 4.4 å›¾æ•°æ®åº“: @ruvector/graph-node

ä¸ºæ”¯æŒçŸ¥è¯†å›¾è°±çš„é«˜æ•ˆå¤šè·³éå†æŸ¥è¯¢ï¼Œæˆ‘ä»¬é€‰æ‹© **@ruvector/graph-node** ä½œä¸ºåµŒå…¥å¼å›¾æ•°æ®åº“ã€‚

> âš ï¸ **é€‰å‹è¯´æ˜**ï¼šKuzu åŸæœ¬æ˜¯ä¼˜é€‰æ–¹æ¡ˆï¼Œä½†å·²äº 2025å¹´10æœˆå½’æ¡£åœæ­¢ç»´æŠ¤ã€‚RuVector Graph æä¾›ç±»ä¼¼çš„ Cypher æŸ¥è¯¢æ”¯æŒå’ŒåµŒå…¥å¼ç‰¹æ€§ï¼Œä¸”ç»´æŠ¤æ´»è·ƒã€‚

#### 4.4.1 ä¸ºä»€ä¹ˆé€‰æ‹© @ruvector/graph-node

| æ–¹æ¡ˆ                        | 3è·³æŸ¥è¯¢æ€§èƒ½ | Node.js æ”¯æŒ       | ä¾èµ–å¤æ‚åº¦  | åµŒå…¥å¼ | ç»´æŠ¤çŠ¶æ€  |
| --------------------------- | ----------- | ------------------ | ----------- | ------ | --------- |
| **@ruvector/graph-node** âœ… | 10-20ms     | âœ… NAPI-RS binding | å•ä¸€ npm åŒ… | âœ…     | æ´»è·ƒç»´æŠ¤  |
| SQLite CTE                  | 200-500ms   | âœ…                 | å·²æœ‰        | âœ…     | éå›¾ä¼˜åŒ–  |
| LevelGraph                  | 60-100ms    | âœ… çº¯ JS           | leveldb     | âœ…     | ç»´æŠ¤å°‘    |
| Kuzu                        | 10-20ms     | âœ… å®˜æ–¹ binding    | å•ä¸€ npm åŒ… | âœ…     | âŒ å·²å½’æ¡£ |
| Neo4j                       | 5-10ms      | âš ï¸ éœ€ JVM          | é‡          | âŒ     | æˆç†Ÿ      |

**RuVector Graph çš„ä¼˜åŠ¿**ï¼š

1. **NAPI-RS åŸç”Ÿç»‘å®š**ï¼šRust å®ç°ï¼Œæ—  WASM å¼€é”€ï¼Œæ€§èƒ½ä¼˜å¼‚
2. **çœŸæ­£åµŒå…¥å¼**ï¼šæ— éœ€ç‹¬ç«‹è¿›ç¨‹ï¼Œç¬¦åˆ"æ— åç«¯æœåŠ¡"åŸåˆ™
3. **Cypher æŸ¥è¯¢è¯­è¨€**ï¼šå…¼å®¹ Neo4j è¯­æ³•ï¼Œè¡¨è¾¾åŠ›å¼ºï¼Œå›¾æ¨¡å¼åŒ¹é…ç›´è§‚
4. **å…¨å¹³å°æ”¯æŒ**ï¼šLinux/macOS/Windows x64/arm64
5. **å†…ç½®å‘é‡æœç´¢**ï¼šæ”¯æŒ k-NN å‘é‡æœç´¢ï¼Œå¯ä¸å›¾éå†ç»“åˆ
6. **æ´»è·ƒç»´æŠ¤**ï¼šMIT åè®®ï¼Œ~25K å‘¨ä¸‹è½½é‡

**æ€§èƒ½åŸºå‡†**ï¼ˆå®˜æ–¹ benchmarkï¼‰ï¼š

| æ“ä½œç±»å‹        | ååé‡          | å»¶è¿Ÿ   |
| --------------- | --------------- | ------ |
| æ‰¹é‡èŠ‚ç‚¹åˆ›å»º    | 131.10K ops/sec | 7.63Î¼s |
| è¾¹åˆ›å»º          | 9.30K ops/sec   | 107Î¼s  |
| k-hop éå†      | 10.28K ops/sec  | 97Î¼s   |
| å‘é‡æœç´¢ (k=10) | 2.35K ops/sec   | 425Î¼s  |

#### 4.4.2 RuVector Graph é›†æˆå®ç°

```typescript
// packages/core/src/indexing/stores/graphStore.ts

import { GraphDatabase } from '@ruvector/graph-node';
import path from 'path';

/**
 * RuVector Graph-based graph storage for code dependency relationships.
 * Stores entities (functions, classes, modules) and their relationships.
 */
export class GraphStore {
  private db: GraphDatabase | null = null;

  constructor(private dbPath: string) {}

  async initialize(): Promise<void> {
    // åˆ›å»ºæ•°æ®åº“ç›®å½•
    const dbDir = path.dirname(this.dbPath);
    await fs.mkdir(dbDir, { recursive: true });

    // åˆå§‹åŒ– RuVector Graph æ•°æ®åº“
    this.db = new GraphDatabase(this.dbPath);

    // åˆ›å»º Schema
    await this.createSchema();
  }

  private async createSchema(): Promise<void> {
    // å®ä½“èŠ‚ç‚¹è¡¨
    await this.db!.execute(`
      CREATE NODE TABLE IF NOT EXISTS Entity (
        id STRING PRIMARY KEY,
        name STRING,
        type STRING,           -- 'module' | 'class' | 'function' | 'method' | 'interface' | 'variable'
        filePath STRING,
        startLine INT64,
        endLine INT64,
        signature STRING,
        docstring STRING,
        chunkId STRING         -- å…³è”çš„ chunk ID
      )
    `);

    // å…³ç³»è¾¹è¡¨
    await this.db!.execute(`
      CREATE REL TABLE IF NOT EXISTS IMPORTS (
        FROM Entity TO Entity,
        line INT64,
        alias STRING
      )
    `);

    await this.db!.execute(`
      CREATE REL TABLE IF NOT EXISTS CALLS (
        FROM Entity TO Entity,
        line INT64
      )
    `);

    await this.db!.execute(`
      CREATE REL TABLE IF NOT EXISTS EXTENDS (
        FROM Entity TO Entity
      )
    `);

    await this.db!.execute(`
      CREATE REL TABLE IF NOT EXISTS IMPLEMENTS (
        FROM Entity TO Entity
      )
    `);

    await this.db!.execute(`
      CREATE REL TABLE IF NOT EXISTS CONTAINS (
        FROM Entity TO Entity
      )
    `);

    await this.db!.execute(`
      CREATE REL TABLE IF NOT EXISTS EXPORTS (
        FROM Entity TO Entity
      )
    `);

    await this.db!.execute(`
      CREATE REL TABLE IF NOT EXISTS USES (
        FROM Entity TO Entity,
        line INT64
      )
    `);

    await this.db!.execute(`
      CREATE REL TABLE IF NOT EXISTS DEFINES (
        FROM Entity TO Entity
      )
    `);
  }

  /**
   * Insert entities in batch.
   */
  async insertEntities(entities: GraphEntity[]): Promise<void> {
    const BATCH_SIZE = 500;

    for (let i = 0; i < entities.length; i += BATCH_SIZE) {
      const batch = entities.slice(i, i + BATCH_SIZE);

      // ä½¿ç”¨ RuVector çš„ COPY FROM æˆ–å‚æ•°åŒ–æ’å…¥
      for (const entity of batch) {
        await this.db!.execute(
          `
          MERGE (e:Entity {id: $id})
          SET e.name = $name,
              e.type = $type,
              e.filePath = $filePath,
              e.startLine = $startLine,
              e.endLine = $endLine,
              e.signature = $signature,
              e.docstring = $docstring,
              e.chunkId = $chunkId
        `,
          {
            id: entity.id,
            name: entity.name,
            type: entity.type,
            filePath: entity.filePath,
            startLine: entity.startLine,
            endLine: entity.endLine,
            signature: entity.signature || null,
            docstring: entity.docstring || null,
            chunkId: entity.chunkId || null,
          },
        );
      }
    }
  }

  /**
   * Insert relations in batch.
   */
  async insertRelations(relations: GraphRelation[]): Promise<void> {
    for (const rel of relations) {
      const query = this.buildRelationQuery(rel);
      await this.db!.execute(query.cypher, query.params);
    }
  }

  private buildRelationQuery(rel: GraphRelation): {
    cypher: string;
    params: Record<string, unknown>;
  } {
    const baseQuery = `
      MATCH (a:Entity {id: $sourceId}), (b:Entity {id: $targetId})
      MERGE (a)-[r:${rel.type}]->(b)
    `;

    const params: Record<string, unknown> = {
      sourceId: rel.sourceId,
      targetId: rel.targetId,
    };

    // æ·»åŠ å…³ç³»å±æ€§
    if (rel.metadata?.line) {
      params.line = rel.metadata.line;
    }
    if (rel.metadata?.alias) {
      params.alias = rel.metadata.alias;
    }

    return { cypher: baseQuery, params };
  }

  /**
   * Execute a Cypher query.
   */
  async query(
    cypher: string,
    params: Record<string, unknown> = {},
  ): Promise<unknown[]> {
    const result = await this.db!.execute(cypher, params);
    const rows: unknown[] = [];

    while (result.hasNext()) {
      rows.push(result.getNext());
    }

    return rows;
  }

  /**
   * Get entity IDs from chunk IDs.
   */
  async getEntitiesByChunkIds(chunkIds: string[]): Promise<string[]> {
    const result = await this.db!.execute(
      `
      MATCH (e:Entity)
      WHERE e.chunkId IN $chunkIds
      RETURN e.id as id
    `,
      { chunkIds },
    );

    const ids: string[] = [];
    while (result.hasNext()) {
      const row = result.getNext();
      ids.push(row.id as string);
    }
    return ids;
  }

  /**
   * Delete all entities and relations for a file (for incremental update).
   */
  async deleteByFilePath(filePath: string): Promise<void> {
    // å…ˆåˆ é™¤ç›¸å…³çš„è¾¹
    await this.db!.execute(
      `
      MATCH (e:Entity {filePath: $filePath})-[r]-()
      DELETE r
    `,
      { filePath },
    );

    // å†åˆ é™¤èŠ‚ç‚¹
    await this.db!.execute(
      `
      MATCH (e:Entity {filePath: $filePath})
      DELETE e
    `,
      { filePath },
    );
  }

  /**
   * Get graph statistics.
   */
  async getStats(): Promise<{ nodeCount: number; edgeCount: number }> {
    const nodeResult = await this.db!.execute(
      'MATCH (n) RETURN count(n) as count',
    );
    const edgeResult = await this.db!.execute(
      'MATCH ()-[r]->() RETURN count(r) as count',
    );

    return {
      nodeCount: nodeResult.getNext().count as number,
      edgeCount: edgeResult.getNext().count as number,
    };
  }

  async close(): Promise<void> {
    if (this.conn) {
      this.conn = null;
    }
    if (this.db) {
      this.db.close();
      this.db = null;
    }
  }
}
```

#### 4.4.3 å­˜å‚¨æ¶æ„æ€»è§ˆ

ä¸‰å±‚å­˜å‚¨æ¶æ„ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           å­˜å‚¨æ¶æ„                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   SQLite            â”‚  â”‚   RuVector Graph    â”‚  â”‚    Zvec             â”‚ â”‚
â”‚  â”‚   (better-sqlite3)  â”‚  â”‚ (@ruvector/graph)   â”‚  â”‚    (NAPI binding)   â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ â€¢ file_meta         â”‚  â”‚ â€¢ Entity nodes      â”‚  â”‚ â€¢ content_embedding â”‚ â”‚
â”‚  â”‚ â€¢ chunks            â”‚  â”‚ â€¢ IMPORTS edges     â”‚  â”‚ â€¢ 1024-dim vectors  â”‚ â”‚
â”‚  â”‚ â€¢ fts_chunks (FTS5) â”‚  â”‚ â€¢ CALLS edges       â”‚  â”‚ â€¢ HNSW index        â”‚ â”‚
â”‚  â”‚ â€¢ embedding_cache   â”‚  â”‚ â€¢ EXTENDS edges     â”‚  â”‚ â€¢ Cosine similarity â”‚ â”‚
â”‚  â”‚ â€¢ index_status      â”‚  â”‚ â€¢ IMPLEMENTS edges  â”‚  â”‚                     â”‚ â”‚
â”‚  â”‚ â€¢ build_checkpoint  â”‚  â”‚ â€¢ CONTAINS edges    â”‚  â”‚                     â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ ç”¨é€”:               â”‚  â”‚ ç”¨é€”:               â”‚  â”‚ ç”¨é€”:               â”‚ â”‚
â”‚  â”‚ - å…ƒæ•°æ®å­˜å‚¨        â”‚  â”‚ - ä¾èµ–å…³ç³»å›¾        â”‚  â”‚ - è¯­ä¹‰å‘é‡æ£€ç´¢      â”‚ â”‚
â”‚  â”‚ - BM25 å…¨æ–‡æœç´¢     â”‚  â”‚ - å¤šè·³å›¾éå†        â”‚  â”‚ - ç›¸ä¼¼ä»£ç å‘ç°      â”‚ â”‚
â”‚  â”‚ - Embedding ç¼“å­˜    â”‚  â”‚ - å­å›¾æå–          â”‚  â”‚                     â”‚ â”‚
â”‚  â”‚ - çŠ¶æ€æŒä¹…åŒ–        â”‚  â”‚ - æœ€çŸ­è·¯å¾„æŸ¥è¯¢      â”‚  â”‚                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚  å­˜å‚¨è·¯å¾„: ~/.qwen-code/index/{projectHash}/                                â”‚
â”‚  â”œâ”€â”€ metadata.db    (SQLite)                                               â”‚
â”‚  â”œâ”€â”€ graph/         (RuVector)                                             â”‚
â”‚  â””â”€â”€ vectors/       (Zvec)                                                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.5 Embedding æœåŠ¡

å¤ç”¨å·²æœ‰çš„ `BaseLlmClient.generateEmbedding()` æ–¹æ³•ï¼Œæ”¯æŒå¹¶å‘è¯·æ±‚ä»¥æå‡æ€§èƒ½ï¼š

```typescript
// packages/core/src/indexing/embeddingService.ts

/**
 * Configuration for EmbeddingService.
 */
interface EmbeddingServiceConfig {
  batchSize: number; // API æ‰¹é‡é™åˆ¶ï¼Œé»˜è®¤ 20
  maxConcurrency: number; // æœ€å¤§å¹¶å‘è¯·æ±‚æ•°ï¼Œé»˜è®¤ 10
  requestTimeoutMs: number; // è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤ 30000ms
  maxRetries: number; // æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ 3
  retryDelayMs: number; // é‡è¯•åˆå§‹å»¶è¿Ÿï¼Œé»˜è®¤ 1000ms
}

/**
 * Generates embeddings for code chunks with caching support.
 *
 * Features:
 * - Two-level caching (memory + SQLite)
 * - Concurrent batch processing with p-map
 * - Automatic retry with exponential backoff
 * - Request timeout handling
 */
class EmbeddingService {
  private readonly config: EmbeddingServiceConfig = {
    batchSize: 20,
    maxConcurrency: 10, // 30 QPS é™åˆ¶ä¸‹ï¼Œ10 å¹¶å‘è¾ƒå®‰å…¨
    requestTimeoutMs: 30000,
    maxRetries: 3,
    retryDelayMs: 1000,
  };

  constructor(
    private readonly llmClient: BaseLlmClient,
    private readonly cache: EmbeddingCache,
  ) {}

  /**
   * Generates embeddings for chunks with caching and concurrency.
   */
  async embedChunks(
    chunks: Chunk[],
  ): Promise<Array<{ chunk: Chunk; embedding: number[] }>> {
    const results: Array<{ chunk: Chunk; embedding: number[] }> = [];
    const uncachedChunks: Chunk[] = [];

    // 1. æ£€æŸ¥ç¼“å­˜
    for (const chunk of chunks) {
      const cacheKey = this.computeEmbeddingCacheKey(chunk);
      const cached = this.cache.getByKey(cacheKey);
      if (cached) {
        results.push({ chunk, embedding: cached });
      } else {
        uncachedChunks.push(chunk);
      }
    }

    // 2. å¹¶å‘æ‰¹é‡è°ƒç”¨ API (ä½¿ç”¨ p-map)
    if (uncachedChunks.length > 0) {
      const newEmbeddings =
        await this.generateConcurrentEmbeddings(uncachedChunks);
      // ... ç¼“å­˜å¹¶æ”¶é›†ç»“æœ
    }

    return results;
  }

  /**
   * Generate embeddings with concurrent batch processing using p-map.
   */
  private async generateConcurrentEmbeddings(
    chunks: Chunk[],
  ): Promise<Array<number[] | null>> {
    const { batchSize, maxConcurrency } = this.config;
    const results: Array<number[] | null> = new Array(chunks.length).fill(null);
    const failedBatches: BatchTask[] = [];

    // åˆ›å»ºæ‰¹æ¬¡ä»»åŠ¡
    const batches = this.createBatchTasks(chunks);

    // ä½¿ç”¨ p-map å¹¶å‘å¤„ç†
    await pMap(
      batches,
      async (batch) => {
        try {
          const embeddings = await this.generateWithRetryAndTimeout(
            batch.texts,
          );
          for (let j = 0; j < embeddings.length; j++) {
            results[batch.batchIndex + j] = embeddings[j];
          }
        } catch (error) {
          failedBatches.push(batch);
        }
      },
      { concurrency: maxConcurrency },
    );

    // é‡è¯•å¤±è´¥çš„æ‰¹æ¬¡
    if (failedBatches.length > 0) {
      await this.retryFailedBatches(failedBatches, results);
    }

    return results;
  }

  /**
   * Calls embedding API with timeout and exponential backoff retry.
   */
  private async generateWithRetryAndTimeout(
    texts: string[],
  ): Promise<number[][]> {
    const { maxRetries, retryDelayMs, requestTimeoutMs } = this.config;

    for (let attempt = 0; attempt < maxRetries; attempt++) {
      try {
        // è¶…æ—¶æ§åˆ¶
        const timeoutPromise = new Promise<never>((_, reject) => {
          setTimeout(
            () => reject(new Error('Request timeout')),
            requestTimeoutMs,
          );
        });

        return await Promise.race([
          this.llmClient.generateEmbedding(texts),
          timeoutPromise,
        ]);
      } catch (error) {
        if (attempt < maxRetries - 1) {
          await sleep(retryDelayMs * Math.pow(2, attempt)); // æŒ‡æ•°é€€é¿
        } else {
          throw error;
        }
      }
    }
    throw new Error('Failed after all retries');
  }

  /**
   * Computes the cache key for embedding.
   * Note: Line numbers are excluded to allow reuse after code refactoring.
   */
  private computeEmbeddingCacheKey(chunk: Chunk): string {
    const input = [
      chunk.filepath, // æ–‡ä»¶è·¯å¾„å½±å“ä¸Šä¸‹æ–‡ç†è§£
      chunk.type, // chunk ç±»å‹å½±å“å…ƒæ•°æ®å‰ç¼€
      chunk.contentHash, // å†…å®¹æœ¬èº«
    ].join('|');

    return crypto.createHash('sha256').update(input).digest('hex').slice(0, 32);
  }

  /**
   * Builds the embedding input with metadata enhancement.
   */
  private buildEmbeddingInput(chunk: Chunk): string {
    const parts = [`File: ${chunk.filepath}`, `Type: ${chunk.type}`];

    if (chunk.metadata.functionName) {
      parts.push(`Function: ${chunk.metadata.functionName}`);
    }
    if (chunk.metadata.className) {
      parts.push(`Class: ${chunk.metadata.className}`);
    }
    if (chunk.metadata.signature) {
      parts.push(`Signature: ${chunk.metadata.signature}`);
    }

    parts.push('', chunk.content);

    return parts.join('\n');
  }
}
```

**æ€§èƒ½ä¼˜åŒ–è¯´æ˜**ï¼š

| ä¼˜åŒ–é¡¹   | åŸå®ç°     | æ–°å®ç°       | æå‡       |
| -------- | ---------- | ------------ | ---------- |
| æ‰¹æ¬¡å»¶è¿Ÿ | 100ms/æ‰¹æ¬¡ | æ— å»¶è¿Ÿ       | -          |
| å¹¶å‘å¤„ç† | ä¸²è¡Œ       | p-map 10å¹¶å‘ | ~10x       |
| è¯·æ±‚è¶…æ—¶ | æ—          | 30s è¶…æ—¶     | é¿å…é˜»å¡   |
| å¤±è´¥å¤„ç† | å•æ¬¡é‡è¯•   | åŒé‡é‡è¯•     | æ›´é«˜æˆåŠŸç‡ |

**ååé‡ä¼°ç®—**ï¼ˆ1000 chunks, batchSize=20, APIå»¶è¿Ÿ300msï¼‰ï¼š

- åŸå®ç°ï¼š50æ‰¹ Ã— (300ms + 100ms) â‰ˆ **20ç§’**
- æ–°å®ç°ï¼š50æ‰¹ / 10å¹¶å‘ Ã— 300ms â‰ˆ **1.5ç§’**

---

## 5. Worker Thread åå°è¿è¡Œæ¶æ„

### 5.1 æ•´ä½“æ¶æ„

ç´¢å¼•æ„å»ºæ˜¯ CPU å’Œ I/O å¯†é›†å‹ä»»åŠ¡ï¼Œå¿…é¡»åœ¨ Worker Thread ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹çš„ç”¨æˆ·äº¤äº’ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              Main Thread                                     â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    IPC (MessagePort)    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ IndexServiceâ”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚      IndexWorker Thread        â”‚  â”‚
â”‚  â”‚  (Facade)   â”‚                         â”‚                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚        â”‚                                 â”‚  â”‚     IndexManager        â”‚   â”‚  â”‚
â”‚        â”‚                                 â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚  â”‚
â”‚        â–¼                                 â”‚  â”‚  â”‚Scannerâ”‚  Chunker  â”‚  â”‚   â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚  â”‚
â”‚  â”‚ /codebase   â”‚                         â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚  â”‚
â”‚  â”‚  Command    â”‚                         â”‚  â”‚  â”‚Embedderâ”‚ Detector â”‚  â”‚   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚  â”‚
â”‚        â”‚                                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚        â–¼                                 â”‚              â”‚                 â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚              â–¼                 â”‚  â”‚
â”‚  â”‚ Retrieval   â”‚â—€â”€â”€â”€ query â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚ Coordinator â”‚                         â”‚  â”‚   MetadataStore (SQLite)â”‚   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚  â”‚   VectorStore (Zvec)    â”‚   â”‚  â”‚
â”‚                                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Worker Thread å®ç°

```typescript
// packages/core/src/indexing/worker/indexWorker.ts

import { parentPort, workerData } from 'worker_threads';
import { IndexManager } from '../IndexManager.js';

// Worker å¯åŠ¨æ—¶åˆå§‹åŒ–
const manager = new IndexManager(
  workerData.projectRoot,
  workerData.projectHash,
);

// æ¶ˆæ¯å¤„ç†
parentPort?.on('message', async (message: WorkerMessage) => {
  try {
    switch (message.type) {
      case 'build':
        await handleBuild(message.payload);
        break;
      case 'incremental_update':
        await handleIncrementalUpdate(message.payload);
        break;
      case 'pause':
        manager.pause();
        postMessage({ type: 'paused' });
        break;
      case 'resume':
        manager.resume();
        postMessage({ type: 'resumed' });
        break;
      case 'cancel':
        await manager.cancel();
        postMessage({ type: 'cancelled' });
        break;
      case 'get_status':
        postMessage({ type: 'status', payload: manager.getStatus() });
        break;
    }
  } catch (error) {
    postMessage({
      type: 'error',
      payload: { message: (error as Error).message },
    });
  }
});

async function handleBuild(payload: BuildPayload): Promise<void> {
  for await (const progress of manager.build(payload)) {
    postMessage({ type: 'progress', payload: progress });
  }
  postMessage({ type: 'build_complete' });
}

async function handleIncrementalUpdate(
  payload: IncrementalPayload,
): Promise<void> {
  for await (const progress of manager.incrementalUpdate(payload.changes)) {
    postMessage({ type: 'progress', payload: progress });
  }
  postMessage({ type: 'update_complete' });
}

function postMessage(msg: WorkerResponse): void {
  parentPort?.postMessage(msg);
}
```

### 5.3 ä¸»çº¿ç¨‹ Facade

````typescript
// packages/core/src/indexing/indexService.ts

import { Worker } from 'worker_threads';
import path from 'path';
import { EventEmitter } from 'events';

/**
 * Facade service for codebase indexing functionality.
 *
 * This service manages the lifecycle of the index worker thread and provides
 * a simple API for controlling index operations. It follows the service pattern
 * used throughout qwen-code.
 *
 * @example
 * ```typescript
 * const indexService = new IndexService(projectRoot, projectHash, config);
 * indexService.on('progress', (progress) => console.log(progress));
 * await indexService.start();
 * ```
 */
export class IndexService extends EventEmitter {
  private worker: Worker | null = null;
  private pollTimer: NodeJS.Timeout | null = null;
  private enabled: boolean = true;
  private status: IndexingProgress = { status: 'idle' /* ... */ };

  private readonly POLL_INTERVAL = 10 * 60 * 1000; // 10 minutes

  /**
   * Creates a new IndexService instance.
   * @param projectRoot The root path of the project to index.
   * @param projectHash A unique hash identifying the project.
   * @param config The index configuration.
   */
  constructor(
    private readonly projectRoot: string,
    private readonly projectHash: string,
    private readonly config: IndexConfig,
  ) {
    super();
  }

  /**
   * Starts the index service and worker thread.
   * If autoIndex is enabled and no index exists, initiates first build.
   * @throws Error if the platform is not supported (Windows).
   */
  async start(): Promise<void> {
    // å¹³å°æ”¯æŒæ€§æ£€æŸ¥ï¼ˆå¤ç”¨å·²æœ‰å·¥å…·ï¼‰
    if (isWindows) {
      this.emit('error', new Error('Codebase Index åŠŸèƒ½æš‚ä¸æ”¯æŒ Windows å¹³å°'));
      return;
    }

    if (!this.config.enabled) {
      this.enabled = false;
      return;
    }

    // å¯åŠ¨ Worker
    this.worker = new Worker(path.join(__dirname, 'worker', 'indexWorker.js'), {
      workerData: {
        projectRoot: this.projectRoot,
        projectHash: this.projectHash,
      },
    });

    this.worker.on('message', this.handleWorkerMessage.bind(this));
    this.worker.on('error', this.handleWorkerError.bind(this));

    // æ£€æŸ¥æ˜¯å¦éœ€è¦é¦–æ¬¡æ„å»º
    const indexExists = await this.checkIndexExists();
    if (!indexExists && this.config.autoIndex) {
      this.build();
    }

    // å¯åŠ¨å®šæ—¶è½®è¯¢
    this.startPolling();
  }

  // åœæ­¢æœåŠ¡
  async stop(): Promise<void> {
    this.stopPolling();
    if (this.worker) {
      await this.worker.terminate();
      this.worker = null;
    }
  }

  // è§¦å‘æ„å»º
  build(): void {
    this.postMessage({ type: 'build', payload: {} });
  }

  // æš‚åœ
  pause(): void {
    this.postMessage({ type: 'pause' });
  }

  // æ¢å¤
  resume(): void {
    this.postMessage({ type: 'resume' });
  }

  // å–æ¶ˆ
  cancel(): void {
    this.postMessage({ type: 'cancel' });
  }

  // å¯ç”¨/ç¦ç”¨
  enable(): void {
    this.enabled = true;
    this.startPolling();
  }

  disable(): void {
    this.enabled = false;
    this.stopPolling();
    this.cancel();
  }

  // è·å–çŠ¶æ€
  getStatus(): IndexingProgress {
    return this.status;
  }

  // å®šæ—¶è½®è¯¢
  private startPolling(): void {
    if (!this.enabled) return;

    this.pollTimer = setInterval(() => {
      this.postMessage({ type: 'incremental_update', payload: {} });
    }, this.POLL_INTERVAL);
  }

  private stopPolling(): void {
    if (this.pollTimer) {
      clearInterval(this.pollTimer);
      this.pollTimer = null;
    }
  }

  // Worker æ¶ˆæ¯å¤„ç†
  private handleWorkerMessage(msg: WorkerResponse): void {
    switch (msg.type) {
      case 'progress':
        this.status = msg.payload;
        this.emit('progress', msg.payload);
        break;
      case 'build_complete':
      case 'update_complete':
        this.status.status = 'done';
        this.emit('complete');
        break;
      case 'error':
        this.status.status = 'error';
        this.status.error = msg.payload.message;
        this.emit('error', msg.payload);
        break;
    }
  }

  private handleWorkerError(error: Error): void {
    this.status.status = 'error';
    this.status.error = error.message;
    this.emit('error', { message: error.message });
  }

  private postMessage(msg: WorkerMessage): void {
    this.worker?.postMessage(msg);
  }
}
````

### 5.4 æ‰¹å¤„ç†å‚æ•°æ±‡æ€»

| é˜¶æ®µ            | æ‰¹å¤„ç†å¤§å°        | å¹¶å‘æ•°       | å»¶è¿Ÿ  | è¯´æ˜                     |
| --------------- | ----------------- | ------------ | ----- | ------------------------ |
| **æ–‡ä»¶æ‰«æ**    | å…¨é‡ä¸€æ¬¡          | 4 (hashè®¡ç®—) | -     | ripgrep æ‰«æ + å¹¶è¡Œ hash |
| **ä»£ç åˆ†å—**    | 100 files/batch   | 1            | -     | AST è§£æ CPU å¯†é›†        |
| **Embedding**   | 20 chunks/batch   | 1            | 100ms | API QPS é™åˆ¶             |
| **SQLite å†™å…¥** | 500 records/batch | 1            | -     | äº‹åŠ¡æ‰¹é‡å†™               |
| **Zvec å†™å…¥**   | 100 docs/batch    | 1            | -     | æ‰¹é‡ insert              |
| **å˜æ›´æ£€æµ‹**    | 10 min            | 1            | -     | å®šæ—¶è½®è¯¢                 |

---

## 6. å­˜å‚¨è®¾è®¡

### 6.1 ç›®å½•ç»“æ„

```
~/.qwen/
â”œâ”€â”€ index/
â”‚   â””â”€â”€ <project_hash>/           # SHA-256(projectRoot) å‰ 16 ä½
â”‚       â”œâ”€â”€ metadata.db           # SQLite: æ–‡ä»¶å…ƒæ•°æ® + chunks + FTS + embedding ç¼“å­˜
â”‚       â””â”€â”€ vectors/              # Zvec: å‘é‡å­˜å‚¨
â”‚           â””â”€â”€ codebase_vectors/
â”‚               â”œâ”€â”€ data/
â”‚               â””â”€â”€ index/
â””â”€â”€ ...

ç¤ºä¾‹:
~/.qwen/index/a1b2c3d4e5f67890/metadata.db
~/.qwen/index/a1b2c3d4e5f67890/vectors/codebase_vectors/
```

### 6.2 Embedding ç¼“å­˜ç­–ç•¥

Embedding è®¡ç®—æ˜¯æœ€è€—æ—¶çš„ç¯èŠ‚ï¼ˆAPI è°ƒç”¨ï¼‰ï¼Œç¼“å­˜è®¾è®¡è‡³å…³é‡è¦ï¼š

```typescript
// packages/core/src/indexing/embeddingCache.ts

/**
 * ä¸¤çº§ç¼“å­˜ç­–ç•¥:
 * 1. SQLite æŒä¹…åŒ–ç¼“å­˜ (embedding_cache è¡¨)
 * 2. å†…å­˜ LRU ç¼“å­˜ (çƒ­ç‚¹æ•°æ®)
 */
class EmbeddingCache {
  // å†…å­˜ LRU: æœ€å¤š 5000 æ¡ï¼Œçº¦ 20MB (1024 dim * 4 bytes * 5000)
  private memoryCache = new LRUCache<string, Float32Array>({
    max: 5000,
    maxSize: 20 * 1024 * 1024,
    sizeCalculation: (value) => value.byteLength,
  });

  constructor(private readonly db: MetadataStore) {}

  async get(contentHash: string): Promise<number[] | null> {
    // 1. å†…å­˜ç¼“å­˜å‘½ä¸­
    const memCached = this.memoryCache.get(contentHash);
    if (memCached) {
      return Array.from(memCached);
    }

    // 2. SQLite ç¼“å­˜å‘½ä¸­
    const dbCached = this.db.getEmbeddingCache(contentHash);
    if (dbCached) {
      // å†™å…¥å†…å­˜ç¼“å­˜
      this.memoryCache.set(contentHash, new Float32Array(dbCached));
      return dbCached;
    }

    return null;
  }

  async set(contentHash: string, embedding: number[]): Promise<void> {
    const typed = new Float32Array(embedding);

    // 1. å†™å…¥å†…å­˜ç¼“å­˜
    this.memoryCache.set(contentHash, typed);

    // 2. å¼‚æ­¥å†™å…¥ SQLite
    setImmediate(() => {
      this.db.setEmbeddingCache(contentHash, embedding);
    });
  }

  // ç¼“å­˜ç»Ÿè®¡
  getStats(): CacheStats {
    return {
      memorySize: this.memoryCache.calculatedSize || 0,
      memoryCount: this.memoryCache.size,
      // dbCount éœ€è¦æŸ¥è¯¢ SQLite
    };
  }
}
```

### 6.3 å­˜å‚¨å®¹é‡ä¼°ç®—

ä»¥ä¸€ä¸ªå…¸å‹çš„ä¸­å‹é¡¹ç›®ï¼ˆ5000 ä¸ªæºæ–‡ä»¶ï¼Œå¹³å‡æ¯æ–‡ä»¶äº§ç”Ÿ 5 ä¸ª chunksï¼‰ä¸ºä¾‹ï¼š

| å­˜å‚¨é¡¹          | å•æ¡å¤§å°        | æ€»æ¡æ•° | æ€»å¤§å°      |
| --------------- | --------------- | ------ | ----------- |
| file_meta       | ~200 bytes      | 5,000  | ~1 MB       |
| chunks          | ~2 KB           | 25,000 | ~50 MB      |
| fts_chunks      | ~1 KB           | 25,000 | ~25 MB      |
| embedding_cache | 4 KB (1024 dim) | 25,000 | ~100 MB     |
| Zvec vectors    | 4 KB + overhead | 25,000 | ~150 MB     |
| **æ€»è®¡**        |                 |        | **~330 MB** |

---

## 7. å®æ–½ TODO List

> ä»¥ä¸‹æ˜¯æŒ‰ä¾èµ–é¡ºåºæ’åˆ—çš„å¯æ‰§è¡Œä»»åŠ¡åˆ—è¡¨ã€‚æ¯ä¸ªæ­¥éª¤åŒ…å«å…·ä½“çš„å®ç°ä»»åŠ¡ã€éªŒè¯æ–¹æ³•å’Œé€šè¿‡æ ‡å‡†ã€‚
> å®Œæˆä¸€ä¸ªæ­¥éª¤çš„æ‰€æœ‰ä»»åŠ¡å¹¶éªŒè¯é€šè¿‡åï¼Œå†è¿›å…¥ä¸‹ä¸€ä¸ªæ­¥éª¤ã€‚
>
> **æ³¨æ„**ï¼šæ€§èƒ½ä¼˜åŒ–å’Œå¤§ä»“åº“æ”¯æŒçš„è€ƒé‡å·²èå…¥å„æ­¥éª¤çš„å…·ä½“å®ç°ä¸­ï¼Œè€Œéä½œä¸ºç‹¬ç«‹æ­¥éª¤ã€‚

### 7.1 Step 1: åŸºç¡€è®¾æ–½ä¸å­˜å‚¨å±‚

**ç›®æ ‡**: å»ºç«‹ç´¢å¼•ç³»ç»Ÿçš„æ•°æ®å­˜å‚¨åŸºç¡€ï¼Œä¸ºåç»­åŠŸèƒ½æä¾›æŒä¹…åŒ–æ”¯æŒã€‚

**å‰ç½®æ¡ä»¶**:

- `zvec` å·²å®‰è£… âœ…
- `better-sqlite3` éœ€å®‰è£…
- `@ruvector/graph-node` éœ€å®‰è£…ï¼ˆå›¾æ•°æ®åº“ï¼‰
- ä»…æ”¯æŒ macOS å’Œ Linux å¹³å°ï¼ˆå¤ç”¨å·²æœ‰ `isWindows` å·¥å…·è¿›è¡Œæ£€æŸ¥ï¼‰

#### ä»»åŠ¡æ¸…å•

| #    | ä»»åŠ¡                             | æ–‡ä»¶è·¯å¾„                                                  | è¯´æ˜                                               |
| ---- | -------------------------------- | --------------------------------------------------------- | -------------------------------------------------- |
| 1.1  | åˆ›å»º indexing æ¨¡å—ç›®å½•ç»“æ„       | `packages/core/src/indexing/`                             | åˆ›å»ºä¸»ç›®å½•ã€`stores/`ã€`worker/` å­ç›®å½•            |
| 1.2  | å®šä¹‰æ ¸å¿ƒç±»å‹å’Œæ¥å£               | `packages/core/src/indexing/types.ts`                     | è§é™„å½• Aï¼Œä½¿ç”¨ `I*` å‰ç¼€å®šä¹‰æ¥å£ï¼ŒåŒ…å«å›¾è°±ç±»å‹     |
| 1.3  | æ·»åŠ  `better-sqlite3` ä¾èµ–       | `packages/core/package.json`                              | `npm install better-sqlite3 @types/better-sqlite3` |
| 1.4  | æ·»åŠ  `@ruvector/graph-node` ä¾èµ– | `packages/core/package.json`                              | `npm install @ruvector/graph-node`                 |
| 1.5  | å®ç° MetadataStore (SQLite)      | `packages/core/src/indexing/stores/metadataStore.ts`      | è¡¨ç»“æ„è§ 4.3 èŠ‚ï¼ŒåŒ…å«æ–­ç‚¹ç»­ä¼ è¡¨                    |
| 1.6  | å®ç° VectorStore (Zvec)          | `packages/core/src/indexing/stores/vectorStore.ts`        | ä½¿ç”¨ NAPI bindingï¼Œæ‰¹é‡æ“ä½œä¼˜åŒ–                    |
| 1.7  | å®ç° GraphStore (RuVector)       | `packages/core/src/indexing/stores/graphStore.ts`         | å›¾æ•°æ®åº“å­˜å‚¨ï¼Œè§ 4.4 èŠ‚                            |
| 1.8  | ç¼–å†™ MetadataStore å•æµ‹          | `packages/core/src/indexing/stores/metadataStore.test.ts` | è¦†ç›– CRUD + FTS æŸ¥è¯¢                               |
| 1.9  | ç¼–å†™ VectorStore å•æµ‹            | `packages/core/src/indexing/stores/vectorStore.test.ts`   | è¦†ç›– insert + query + delete                       |
| 1.10 | ç¼–å†™ GraphStore å•æµ‹             | `packages/core/src/indexing/stores/graphStore.test.ts`    | è¦†ç›–èŠ‚ç‚¹/è¾¹ CRUD + å›¾æŸ¥è¯¢                          |

#### éªŒè¯è®¡åˆ’

```bash
# 1. æ£€æŸ¥ç›®å½•ç»“æ„
ls -la packages/core/src/indexing/
# é¢„æœŸ: types.ts, stores/, worker/

# 2. æ£€æŸ¥ä¾èµ–å®‰è£…
cat packages/core/package.json | grep better-sqlite3
# é¢„æœŸ: "better-sqlite3": "^x.x.x"

# 3. è¿è¡Œå•å…ƒæµ‹è¯•
npm test -- packages/core/src/indexing/stores/metadataStore.test.ts
npm test -- packages/core/src/indexing/stores/vectorStore.test.ts
# é¢„æœŸ: å…¨éƒ¨é€šè¿‡

# 4. æ‰‹åŠ¨éªŒè¯ (å¯é€‰)
node -e "
const { MetadataStore } = require('./packages/core/dist/indexing/stores/metadataStore');
const store = new MetadataStore('/tmp/test-index');
store.upsertFile({ path: 'test.ts', contentHash: 'abc', lastModified: Date.now(), size: 100 });
console.log(store.getFile('test.ts')); // åº”è¾“å‡ºæ–‡ä»¶è®°å½•
"

# 5. æµ‹è¯•å¹³å°æ£€æŸ¥ï¼ˆä½¿ç”¨ç°æœ‰å·¥å…·ï¼‰
node -e "
const { isWindows } = require('./packages/vscode-ide-companion/dist/utils/platform');
console.log('Is Windows:', isWindows);
// åœ¨ macOS/Linux ä¸Šåº”è¾“å‡º: Is Windows: false
// åœ¨ Windows ä¸Šåº”è¾“å‡º: Is Windows: true
"
```

**é€šè¿‡æ ‡å‡†**:

- [ ] ç›®å½•ç»“æ„å®Œæ•´
- [ ] ä¾èµ–å®‰è£…æˆåŠŸï¼ˆbetter-sqlite3, @ruvector/graph-nodeï¼‰
- [ ] MetadataStore å•æµ‹å…¨éƒ¨é€šè¿‡ï¼ˆâ‰¥5 ä¸ªç”¨ä¾‹ï¼‰
- [ ] VectorStore å•æµ‹å…¨éƒ¨é€šè¿‡ï¼ˆâ‰¥4 ä¸ªç”¨ä¾‹ï¼‰
- [ ] GraphStore å•æµ‹å…¨éƒ¨é€šè¿‡ï¼ˆâ‰¥5 ä¸ªç”¨ä¾‹ï¼‰

---

### 7.2 Step 2: ç´¢å¼•æ„å»ºæ ¸å¿ƒï¼ˆå«æ™ºèƒ½åˆ†å—ä¸å®ä½“æå–ï¼‰

**ç›®æ ‡**: å®ç°æ–‡ä»¶æ‰«æã€æ™ºèƒ½åˆ†å—ã€Embedding ç”Ÿæˆã€å®ä½“å…³ç³»æå–çš„æ ¸å¿ƒæµæ°´çº¿ã€‚

**å‰ç½®æ¡ä»¶**: Step 1 å®Œæˆ

#### ä»»åŠ¡æ¸…å•

| #    | ä»»åŠ¡                          | æ–‡ä»¶è·¯å¾„                                             | è¯´æ˜                                                                                       |
| ---- | ----------------------------- | ---------------------------------------------------- | ------------------------------------------------------------------------------------------ |
| 2.1  | å®ç° FileScanner              | `packages/core/src/indexing/fileScanner.ts`          | å¤ç”¨ `FileDiscoveryService` + `ripgrepUtils`                                               |
| 2.2  | æ·»åŠ  Tree-sitter ä¾èµ–         | `packages/core/package.json`                         | `npm install tree-sitter tree-sitter-typescript tree-sitter-javascript tree-sitter-python` |
| 2.3  | å®ç° ChunkingService (åŒæ¨¡å¼) | `packages/core/src/indexing/chunkingService.ts`      | è¡Œåˆ†å— + AST åˆ†å—ï¼ˆå‡½æ•°/ç±»è¾¹ç•Œï¼‰                                                           |
| 2.4  | å®ç° EntityExtractor          | `packages/core/src/indexing/entityExtractor.ts`      | AST å®ä½“æå–ï¼ˆå‡½æ•°/ç±»/æ¨¡å—/è°ƒç”¨/ç»§æ‰¿/å¯¼å…¥ï¼‰ï¼Œè§ 3.5.2                                      |
| 2.5  | å®ç° EmbeddingCache           | `packages/core/src/indexing/embeddingCache.ts`       | å†…å­˜ LRU + SQLite æŒä¹…åŒ–ï¼Œè§ 6.2 èŠ‚                                                        |
| 2.6  | å®ç° EmbeddingService         | `packages/core/src/indexing/embeddingService.ts`     | è°ƒç”¨ `BaseLlmClient.generateEmbedding`ï¼Œå¸¦ç¼“å­˜å’Œæ‰¹é‡ï¼Œä½¿ç”¨ä¼˜åŒ–çš„ç¼“å­˜é”®                     |
| 2.7  | å®ç° IndexManager             | `packages/core/src/indexing/indexManager.ts`         | åè°ƒ Scannerâ†’Chunkerâ†’EntityExtractorâ†’Embedderâ†’Store                                        |
| 2.8  | ç¼–å†™ ChunkingService å•æµ‹     | `packages/core/src/indexing/chunkingService.test.ts` | è¦†ç›–è¡Œåˆ†å— + AST åˆ†å—                                                                      |
| 2.9  | ç¼–å†™ EntityExtractor å•æµ‹     | `packages/core/src/indexing/entityExtractor.test.ts` | è¦†ç›–å‡½æ•°/ç±»/å¯¼å…¥æå–                                                                       |
| 2.10 | æ·»åŠ ç´¢å¼•é…ç½®åˆ° Config         | `packages/core/src/config/config.ts`                 | `codebaseIndex` é…ç½®é¡¹ï¼ŒåŒ…å«å›¾è°±å¼€å…³                                                       |
| 2.11 | å®ç°å¤§ä»“åº“æµå¼å¤„ç†            | `IndexManager.buildStreaming()`                      | è¶…è¿‡ 50,000 æ–‡ä»¶æ—¶ä½¿ç”¨æµå¼å¤„ç†ï¼Œé¿å…å†…å­˜æº¢å‡º                                               |

#### éªŒè¯è®¡åˆ’

```bash
# 1. æ£€æŸ¥ Tree-sitter ä¾èµ–
cat packages/core/package.json | grep tree-sitter
# é¢„æœŸ: tree-sitter, tree-sitter-typescript ç­‰

# 2. è¿è¡Œ ChunkingService å•æµ‹
npm test -- packages/core/src/indexing/ChunkingService.test.ts
# é¢„æœŸ: å…¨éƒ¨é€šè¿‡

# 3. éªŒè¯ AST åˆ†å— (TypeScript æ–‡ä»¶)
node -e "
const { ChunkingService } = require('./packages/core/dist/indexing/ChunkingService');
const chunker = new ChunkingService();
const code = 'function foo() { return 1; }\nclass Bar { method() {} }';
const chunks = chunker.astChunk(code, 'typescript');
console.log(chunks.length); // é¢„æœŸ: 2 (function + class)
console.log(chunks[0].type); // é¢„æœŸ: 'function'
"

# 4. éªŒè¯ IndexManager å®Œæ•´æµç¨‹ (å°è§„æ¨¡)
node -e "
const { IndexManager } = require('./packages/core/dist/indexing/IndexManager');
const manager = new IndexManager({ workspacePath: './packages/core', /* mock embedder */ });
// é¢„æœŸ: ä¸æŠ¥é”™ï¼Œå®Œæˆæ‰«æå’Œåˆ†å—
"
```

**é€šè¿‡æ ‡å‡†**:

- [ ] FileScanner å¯æ‰«æé¡¹ç›®ã€æ­£ç¡®è¿‡æ»¤ .gitignoreï¼ˆå¤ç”¨ FileDiscoveryServiceï¼‰
- [ ] ChunkingService è¡Œåˆ†å—äº§ç”Ÿåˆç†å¤§å°çš„ chunksï¼ˆ~512 tokensï¼‰
- [ ] ChunkingService AST åˆ†å—èƒ½è¯†åˆ« TS/JS å‡½æ•°å’Œç±»è¾¹ç•Œ
- [ ] EmbeddingCache å†…å­˜/SQLite åŒå±‚ç¼“å­˜å·¥ä½œæ­£å¸¸ï¼Œç¼“å­˜é”®åŒ…å«æ–‡ä»¶è·¯å¾„å’Œç±»å‹
- [ ] ChunkingService å•æµ‹å…¨éƒ¨é€šè¿‡
- [ ] å¤§ä»“åº“ï¼ˆ>50,000 æ–‡ä»¶ï¼‰ä¸ä¼šå¯¼è‡´å†…å­˜æº¢å‡º

---

### 7.3 Step 3: Worker Thread æ¶æ„ä¸æ–­ç‚¹ç»­ä¼ 

**ç›®æ ‡**: å°†è€—æ—¶çš„ç´¢å¼•æ„å»ºç§»åˆ° Worker Threadï¼Œä¿æŒä¸»çº¿ç¨‹å“åº”æ€§ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ã€‚

**å‰ç½®æ¡ä»¶**: Step 2 å®Œæˆ

#### ä»»åŠ¡æ¸…å•

| #   | ä»»åŠ¡                       | æ–‡ä»¶è·¯å¾„                                           | è¯´æ˜                                           |
| --- | -------------------------- | -------------------------------------------------- | ---------------------------------------------- |
| 3.1 | å®ç° indexWorker           | `packages/core/src/indexing/worker/indexWorker.ts` | Worker å…¥å£ï¼Œæ¥æ”¶æ¶ˆæ¯æ‰§è¡Œæ„å»º                  |
| 3.2 | å®ç° IndexService (Facade) | `packages/core/src/indexing/IndexService.ts`       | ä¸»çº¿ç¨‹ APIï¼Œç®¡ç† Worker ç”Ÿå‘½å‘¨æœŸï¼Œéµå¾ªæœåŠ¡æ¨¡å¼ |
| 3.3 | å®ç°è¿›åº¦ä¸ŠæŠ¥æœºåˆ¶           | `IndexManager` â†’ `IndexService`                    | å®æ—¶æ¨é€ `IndexingProgress`                    |
| 3.4 | å®ç°æš‚åœ/æ¢å¤/å–æ¶ˆæ§åˆ¶     | `IndexManager` + `IndexService`                    | pause/resume/cancel å‘½ä»¤                       |
| 3.5 | å®ç°æ–­ç‚¹ç»­ä¼ æœºåˆ¶           | `packages/core/src/indexing/CheckpointManager.ts`  | è®°å½•æ„å»ºè¿›åº¦ï¼Œå´©æºƒåå¯æ¢å¤                     |
| 3.6 | å®ç° Worker é”™è¯¯æ¢å¤       | `IndexService`                                     | Worker å´©æºƒæ—¶è‡ªåŠ¨é‡å¯å¹¶ä»æ–­ç‚¹æ¢å¤              |

#### éªŒè¯è®¡åˆ’

```bash
# 1. éªŒè¯ Worker å¯åŠ¨
node -e "
const { IndexService } = require('./packages/core/dist/indexing/IndexService');
const service = new IndexService({ workspacePath: './packages/core' });
service.on('progress', (p) => console.log(p.status, p.overallProgress));
service.startBuild();
// é¢„æœŸ: è¾“å‡º scanning 0%, chunking 25%, embedding 50%, ... done 100%
"

# 2. éªŒè¯æš‚åœ/æ¢å¤
node -e "
const { IndexService } = require('./packages/core/dist/indexing/IndexService');
const service = new IndexService({ workspacePath: './packages/core' });
service.startBuild();
setTimeout(() => service.pause(), 1000);
setTimeout(() => console.log(service.getStatus()), 1500); // é¢„æœŸ: status = 'paused'
setTimeout(() => service.resume(), 2000);
"

# 3. éªŒè¯æ–­ç‚¹ç»­ä¼ 
# a) å¼€å§‹æ„å»ºï¼Œä¸­é€” kill è¿›ç¨‹
# b) é‡æ–°å¯åŠ¨ï¼ŒéªŒè¯ä»æ–­ç‚¹ç»§ç»­è€Œéé‡æ–°å¼€å§‹

# 3. éªŒè¯ä¸»çº¿ç¨‹å“åº”æ€§
# å¯åŠ¨æ„å»ºåï¼Œä¸»çº¿ç¨‹ä»å¯å¤„ç†å…¶ä»–äº‹ä»¶ï¼ˆå¦‚ç”¨æˆ·è¾“å…¥ï¼‰
```

**é€šè¿‡æ ‡å‡†**:

- [ ] IndexService.startBuild() åœ¨ Worker ä¸­æ‰§è¡Œï¼Œä¸»çº¿ç¨‹ä¸é˜»å¡
- [ ] è¿›åº¦å›è°ƒæ­£ç¡®è§¦å‘ï¼Œå„é˜¶æ®µè¿›åº¦é€’å¢
- [ ] pause/resume/cancel å‘½ä»¤ç”Ÿæ•ˆ
- [ ] Worker å´©æºƒå IndexService èƒ½æ£€æµ‹å¹¶æŠ¥å‘Šé”™è¯¯

---

### 7.4 Step 4: å˜æ›´æ£€æµ‹ä¸å¢é‡æ›´æ–°

**ç›®æ ‡**: å®ç°åŸºäºè½®è¯¢çš„å˜æ›´æ£€æµ‹ï¼Œæ”¯æŒå¢é‡ç´¢å¼•æ›´æ–°ã€‚

**å‰ç½®æ¡ä»¶**: Step 3 å®Œæˆ

#### ä»»åŠ¡æ¸…å•

| #   | ä»»åŠ¡                     | æ–‡ä»¶è·¯å¾„                                            | è¯´æ˜                                |
| --- | ------------------------ | --------------------------------------------------- | ----------------------------------- |
| 4.1 | å®ç° ChangeDetector      | `packages/core/src/indexing/ChangeDetector.ts`      | å¯¹æ¯”å½“å‰æ–‡ä»¶ä¸ metadata.db ä¸­çš„è®°å½• |
| 4.2 | å®ç°å¢é‡æ›´æ–°é€»è¾‘         | `IndexManager.incrementalUpdate()`                  | åªå¤„ç† added/modified/deleted       |
| 4.3 | å®ç° 10 åˆ†é’Ÿè½®è¯¢         | `IndexService.startPolling()`                       | setInterval è§¦å‘ ChangeDetector     |
| 4.4 | å®ç°åˆ†æ”¯åˆ‡æ¢æ£€æµ‹         | `packages/core/src/indexing/BranchHandler.ts`       | Git HEAD å˜åŒ–æ—¶è§¦å‘å®Œæ•´å˜æ›´æ£€æµ‹     |
| 4.5 | ç¼–å†™ ChangeDetector å•æµ‹ | `packages/core/src/indexing/ChangeDetector.test.ts` | è¦†ç›–å„ç§å˜æ›´åœºæ™¯                    |

#### éªŒè¯è®¡åˆ’

```bash
# 1. éªŒè¯å˜æ›´æ£€æµ‹
node -e "
const { ChangeDetector } = require('./packages/core/dist/indexing/ChangeDetector');
const detector = new ChangeDetector(metadataStore, '/path/to/workspace');
const changes = await detector.detectChanges();
console.log(changes); // é¢„æœŸ: { added: [...], modified: [...], deleted: [...] }
"

# 2. éªŒè¯å¢é‡æ›´æ–°
# a) å®Œæˆåˆå§‹æ„å»º
# b) æ·»åŠ ä¸€ä¸ªæ–°æ–‡ä»¶
# c) æ‰‹åŠ¨è§¦å‘å¢é‡æ›´æ–°
# d) éªŒè¯åªå¤„ç†äº†æ–°æ–‡ä»¶

# 3. éªŒè¯è½®è¯¢
node -e "
const { IndexService } = require('./packages/core/dist/indexing/IndexService');
const service = new IndexService({ workspacePath: './', pollIntervalMs: 5000 }); // 5s for test
service.on('incremental_complete', () => console.log('poll triggered'));
service.startPolling();
// é¢„æœŸ: æ¯ 5 ç§’è¾“å‡º 'poll triggered'ï¼ˆå¦‚æœ‰å˜æ›´ï¼‰
"

# 4. è¿è¡Œ ChangeDetector å•æµ‹
npm test -- packages/core/src/indexing/ChangeDetector.test.ts
```

**é€šè¿‡æ ‡å‡†**:

- [ ] ChangeDetector æ­£ç¡®è¯†åˆ«æ–°å¢ã€ä¿®æ”¹ã€åˆ é™¤çš„æ–‡ä»¶
- [ ] å¢é‡æ›´æ–°åªå¤„ç†å˜æ›´æ–‡ä»¶ï¼Œè€—æ—¶æ˜æ˜¾å°‘äºå…¨é‡æ„å»º
- [ ] è½®è¯¢æŒ‰é…ç½®é—´éš”è§¦å‘
- [ ] åˆ†æ”¯åˆ‡æ¢æ—¶è‡ªåŠ¨è§¦å‘å˜æ›´æ£€æµ‹
- [ ] ChangeDetector å•æµ‹å…¨éƒ¨é€šè¿‡

---

### 7.5 Step 5: æ£€ç´¢åŠŸèƒ½ï¼ˆå« Query å¢å¼ºä¸å›¾éå†ï¼‰

**ç›®æ ‡**: å®ç°æ··åˆæ£€ç´¢ï¼ˆBM25 + Vector + Recentï¼‰ï¼Œæ”¯æŒæŸ¥è¯¢æ‰©å±•ã€RRF èåˆå’Œå›¾è°±æ‰©å±•ã€‚

**å‰ç½®æ¡ä»¶**: Step 4 å®Œæˆï¼ˆç´¢å¼•æ•°æ®å·²å­˜åœ¨ï¼‰

#### ä»»åŠ¡æ¸…å•

| #    | ä»»åŠ¡                       | æ–‡ä»¶è·¯å¾„                                              | è¯´æ˜                                        |
| ---- | -------------------------- | ----------------------------------------------------- | ------------------------------------------- |
| 5.1  | å®ç° QueryEnhancer         | `packages/core/src/indexing/queryEnhancer.ts`         | åŒä¹‰è¯æ‰©å±•ã€æœ¯è¯­è§„èŒƒåŒ–                      |
| 5.2  | å®ç° GraphTraverser        | `packages/core/src/indexing/graphTraverser.ts`        | å¤šè·³å›¾éå†ã€å­å›¾æå–ï¼Œè§ 3.5.3 èŠ‚           |
| 5.3  | å®ç° RetrievalService      | `packages/core/src/indexing/retrievalService.ts`      | æ··åˆæ£€ç´¢æœåŠ¡ï¼Œéµå¾ª \*Service å‘½åæ¨¡å¼       |
| 5.4  | å®ç° BM25 æ£€ç´¢             | `RetrievalService.bm25Search()`                       | åŸºäº FTS5 çš„å…¨æ–‡æ£€ç´¢                        |
| 5.5  | å®ç°å‘é‡æ£€ç´¢               | `RetrievalService.vectorSearch()`                     | Zvec è¿‘é‚»æœç´¢                               |
| 5.6  | å®ç°æœ€è¿‘ç¼–è¾‘æ£€ç´¢           | `RetrievalService.recentFilesSearch()`                | åŸºäº last_modified æ’åº                     |
| 5.7  | å®ç° RRF èåˆ              | `RetrievalService.rrfFusion()`                        | k=60ï¼Œè§ 3.4.1 èŠ‚                           |
| 5.8  | å®ç°å›¾æ‰©å±•æ£€ç´¢             | `RetrievalService.expandWithGraph()`                  | ä»ç§å­å—å‡ºå‘ï¼Œæ²¿ä¾èµ–å…³ç³»æ‰©å±•ï¼Œè§ 3.5.4      |
| 5.9  | å®ç° Context Builder       | `packages/core/src/indexing/contextBuilder.ts`        | å»é‡ã€æˆªæ–­ã€æ ¼å¼åŒ–ä¸º LLM ä¸Šä¸‹æ–‡ï¼ˆå«å›¾è§†å›¾ï¼‰ |
| 5.10 | ç¼–å†™ GraphTraverser å•æµ‹   | `packages/core/src/indexing/graphTraverser.test.ts`   | è¦†ç›–å¤šè·³éå†ã€å­å›¾æå–                      |
| 5.11 | ç¼–å†™ RetrievalService å•æµ‹ | `packages/core/src/indexing/retrievalService.test.ts` | è¦†ç›–å„æ£€ç´¢è·¯å¾„                              |

#### éªŒè¯è®¡åˆ’

```bash
# 1. éªŒè¯ BM25 æ£€ç´¢
node -e "
const { RetrievalService } = require('./packages/core/dist/indexing/retrievalService');
const service = new RetrievalService(metadataStore, vectorStore, graphStore);
const results = await service.bm25Search('function handler');
console.log(results.length, results[0]?.content.slice(0, 100));
"

# 2. éªŒè¯å‘é‡æ£€ç´¢
node -e "
const results = await service.vectorSearch('ç”¨æˆ·è®¤è¯é€»è¾‘');
console.log(results.length, results[0]?.score);
"

# 3. éªŒè¯ RRF èåˆ
node -e "
const results = await service.retrieve('how does authentication work');
console.log(results.map(r => ({ path: r.filePath, score: r.fusedScore })));
// é¢„æœŸ: æŒ‰ fusedScore é™åºæ’åˆ—
"

# 4. éªŒè¯å›¾æ‰©å±•æ£€ç´¢
node -e "
const results = await service.retrieve('how does authentication work', { enableGraph: true, graphDepth: 2 });
console.log('Chunks:', results.chunks.length);
console.log('Graph nodes:', results.subgraph?.entities.length);
console.log('Graph edges:', results.subgraph?.relations.length);
// é¢„æœŸ: è¿”å›ä»£ç å— + ç›¸å…³çš„ä¾èµ–å›¾è°±
"

# 5. éªŒè¯ Context Builderï¼ˆå«å›¾è§†å›¾ï¼‰
node -e "
const result = await service.retrieve('authentication');
console.log('Text View length:', result.textView.length);
console.log('Graph View:', result.graphView ? 'present' : 'null');
// é¢„æœŸ: textView åŒ…å«ä»£ç ï¼ŒgraphView åŒ…å« Mermaid å›¾
"

# 6. è¿è¡Œå•æµ‹
npm test -- packages/core/src/indexing/graphTraverser.test.ts
npm test -- packages/core/src/indexing/retrievalService.test.ts
```

**é€šè¿‡æ ‡å‡†**:

- [ ] BM25 æ£€ç´¢è¿”å›ç›¸å…³ç»“æœ
- [ ] å‘é‡æ£€ç´¢è¿”å›è¯­ä¹‰ç›¸å…³ç»“æœ
- [ ] RRF èåˆåçš„ç»“æœæ¯”å•è·¯æ£€ç´¢æ›´å‡†ç¡®
- [ ] å›¾æ‰©å±•èƒ½æ­£ç¡®è¿”å›ç›¸å…³å®ä½“å’Œå…³ç³»
- [ ] GraphTraverser å•æµ‹å…¨éƒ¨é€šè¿‡ï¼ˆâ‰¥4 ä¸ªç”¨ä¾‹ï¼‰
- [ ] Context Builder è¾“å‡º textView + graphView
- [ ] RetrievalService å•æµ‹å…¨éƒ¨é€šè¿‡

---

### 7.6 Step 6: CLI é›†æˆ

**ç›®æ ‡**: å°†ç´¢å¼•åŠŸèƒ½é›†æˆåˆ° CLI åº”ç”¨ï¼Œæä¾›ç”¨æˆ·å¯è§çš„å‘½ä»¤å’ŒçŠ¶æ€æ˜¾ç¤ºã€‚éµå¾ªç°æœ‰çš„å‘½ä»¤ç³»ç»Ÿæ¶æ„ï¼ˆICommandLoader æ¨¡å¼ï¼‰ã€‚

**å‰ç½®æ¡ä»¶**: Step 5 å®Œæˆ

#### ä»»åŠ¡æ¸…å•

| #   | ä»»åŠ¡                              | æ–‡ä»¶è·¯å¾„                                             | è¯´æ˜                                        |
| --- | --------------------------------- | ---------------------------------------------------- | ------------------------------------------- |
| 6.1 | å®ç° `/codebase` å‘½ä»¤             | `packages/cli/src/ui/commands/codebaseCommand.ts`    | å­å‘½ä»¤: status, rebuild, pause, resume      |
| 6.2 | å®ç° CodebaseCommandLoader        | `packages/cli/src/services/CodebaseCommandLoader.ts` | éµå¾ª ICommandLoader æ¥å£                    |
| 6.3 | æ³¨å†Œ Loader åˆ° CommandService     | `packages/cli/src/ui/commands/index.ts`              | åœ¨ loaders æ•°ç»„ä¸­æ·»åŠ  CodebaseCommandLoader |
| 6.4 | é›†æˆ IndexService åˆ° CLI å¯åŠ¨æµç¨‹ | `packages/cli/src/core/initializer.ts`               | åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ– IndexService               |
| 6.5 | å®ç°ç´¢å¼•çŠ¶æ€ UI ç»„ä»¶              | `packages/cli/src/ui/components/IndexStatus.tsx`     | çŠ¶æ€æ æ˜¾ç¤ºï¼šidle/scanning 5%/done           |
| 6.6 | å®ç° `@codebase` Context Provider | `packages/cli/src/context/codebaseProvider.ts`       | æ”¯æŒ `@codebase æŸ¥è¯¢` è¯­æ³•                  |
| 6.7 | ç¼–å†™ CLI é›†æˆæµ‹è¯•                 | `integration-tests/codebase-index.test.ts`           | E2E: å¯åŠ¨â†’æ„å»ºâ†’æ£€ç´¢â†’éªŒè¯ç»“æœ                |

#### éªŒè¯è®¡åˆ’

```bash
# 1. éªŒè¯å‘½ä»¤æ³¨å†Œ
node packages/cli/dist/gemini.js
# è¾“å…¥: /help
# é¢„æœŸ: å‘½ä»¤åˆ—è¡¨ä¸­åŒ…å« /codebase

# 2. éªŒè¯ /codebase å‘½ä»¤
# è¾“å…¥: /codebase status
# é¢„æœŸ: æ˜¾ç¤ºå½“å‰ç´¢å¼•çŠ¶æ€

# è¾“å…¥: /codebase rebuild
# é¢„æœŸ: è§¦å‘é‡å»ºï¼Œæ˜¾ç¤ºè¿›åº¦

# 3. éªŒè¯çŠ¶æ€æ 
# æ„å»ºè¿‡ç¨‹ä¸­ï¼Œåº•éƒ¨çŠ¶æ€æ æ˜¾ç¤º "Indexing: 45%"

# 4. éªŒè¯ @codebase Context
# è¾“å…¥: @codebase ç”¨æˆ·è®¤è¯æ˜¯æ€ä¹ˆå®ç°çš„
# é¢„æœŸ: è‡ªåŠ¨æ£€ç´¢ç›¸å…³ä»£ç ç‰‡æ®µï¼Œæ·»åŠ åˆ°ä¸Šä¸‹æ–‡

# 5. è¿è¡Œ E2E æµ‹è¯•
npm test -- integration-tests/codebase-index.test.ts
```

**é€šè¿‡æ ‡å‡†**:

- [ ] `/codebase` å‘½ä»¤å¯è¯†åˆ«å’Œæ‰§è¡Œ
- [ ] `/codebase status` æ˜¾ç¤ºæ­£ç¡®çš„ç´¢å¼•çŠ¶æ€
- [ ] `/codebase rebuild` è§¦å‘é‡å»ºå¹¶æ˜¾ç¤ºè¿›åº¦
- [ ] çŠ¶æ€æ å®æ—¶æ›´æ–°ç´¢å¼•è¿›åº¦
- [ ] `@codebase` è¯­æ³•æ­£ç¡®è§¦å‘æ£€ç´¢
- [ ] E2E æµ‹è¯•é€šè¿‡

---

### 7.7 Step 7: æ–‡æ¡£ä¸æ”¶å°¾

**ç›®æ ‡**: å®Œå–„æ–‡æ¡£ï¼Œç¡®ä¿åŠŸèƒ½å¯ç”¨ã€å¯ç»´æŠ¤ã€‚

**å‰ç½®æ¡ä»¶**: Step 6 å®Œæˆ

#### ä»»åŠ¡æ¸…å•

| #   | ä»»åŠ¡            | æ–‡ä»¶è·¯å¾„                                  | è¯´æ˜                         |
| --- | --------------- | ----------------------------------------- | ---------------------------- |
| 7.1 | ç¼–å†™ç”¨æˆ·æ–‡æ¡£    | `docs/users/codebase-index.md`            | åŠŸèƒ½è¯´æ˜ã€ä½¿ç”¨æ–¹æ³•ã€é…ç½®æŒ‡å— |
| 7.2 | æ›´æ–° CLI README | `packages/cli/README.md`                  | æ·»åŠ  codebase index åŠŸèƒ½è¯´æ˜ |
| 7.3 | æ·»åŠ é…ç½®ç¤ºä¾‹    | `docs/users/configuration.md`             | codebaseIndex é…ç½®é¡¹è¯´æ˜     |
| 7.4 | æ€§èƒ½åŸºå‡†æµ‹è¯•    | `packages/core/src/indexing/benchmark.ts` | è®°å½•å…¸å‹é¡¹ç›®çš„æ„å»º/æ£€ç´¢è€—æ—¶  |
| 7.5 | ä»£ç å®¡æŸ¥ä¸æ¸…ç†  | å…¨éƒ¨ indexing æ¨¡å—                        | ç§»é™¤ console.logã€æ·»åŠ  JSDoc |

#### éªŒè¯è®¡åˆ’

```bash
# 1. æ£€æŸ¥æ–‡æ¡£
cat docs/users/codebase-index.md
# é¢„æœŸ: åŒ…å«åŠŸèƒ½ä»‹ç»ã€å¿«é€Ÿå¼€å§‹ã€é…ç½®è¯´æ˜ã€å¸¸è§é—®é¢˜

# 2. è¿è¡Œå…¨éƒ¨æµ‹è¯•
npm test

# 3. è¿è¡ŒåŸºå‡†æµ‹è¯•
node packages/core/src/indexing/benchmark.ts --workspace ./packages/core
# é¢„æœŸè¾“å‡º:
# Files: 150, Chunks: 800
# Build time: 45s
# Query time (avg): 120ms

# 4. ä»£ç è´¨é‡æ£€æŸ¥
npm run lint
# é¢„æœŸ: æ—  error
```

**é€šè¿‡æ ‡å‡†**:

- [ ] ç”¨æˆ·æ–‡æ¡£å®Œæ•´ä¸”å‡†ç¡®
- [ ] å…¨éƒ¨å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] E2E æµ‹è¯•é€šè¿‡
- [ ] åŸºå‡†æµ‹è¯•ç»“æœè®°å½•åœ¨æ–‡æ¡£ä¸­
- [ ] Lint æ—  error

---

## 8. å‚è€ƒèµ„æ–™

1. [Continue - Codebase Indexing](https://github.com/continuedev/continue/tree/main/core/indexing)
2. [DeepWiki RAG æœ€ä½³å®è·µ](å†…éƒ¨æ–‡æ¡£ - é¢„æ£€ç´¢é˜¶æ®µ + æ£€ç´¢é˜¶æ®µ)
3. [Zvec Documentation](https://zvec.org/en/docs/)
4. [Tree-sitter](https://tree-sitter.github.io/tree-sitter/)
5. [SQLite FTS5](https://www.sqlite.org/fts5.html)
6. [RRF - Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)

---

## 9. é™„å½•

### A. å®Œæ•´ç±»å‹å®šä¹‰

> **å‘½åè§„èŒƒ**ï¼šéµå¾ª qwen-code ç°æœ‰é£æ ¼ï¼Œæ¥å£ä½¿ç”¨ `I*` å‰ç¼€ï¼ˆå¦‚ `IFileScanner`ï¼‰ï¼ŒæœåŠ¡ç±»ä½¿ç”¨ `*Service` åç¼€ã€‚

```typescript
// packages/core/src/indexing/types.ts

/**
 * @license
 * Copyright 2025 Qwen
 * SPDX-License-Identifier: Apache-2.0
 */

// ===== æ¥å£å®šä¹‰ =====

/**
 * Interface for file scanning operations.
 * Implementations should handle .gitignore and .qwenignore filtering.
 */
export interface IFileScanner {
  scanFiles(projectRoot: string): Promise<FileMetadata[]>;
  countFiles(projectRoot: string): Promise<number>;
}

/**
 * Interface for code chunking operations.
 */
export interface IChunkingService {
  chunkFile(filepath: string, content: string): Promise<Chunk[]>;
}

/**
 * Interface for embedding generation.
 */
export interface IEmbeddingService {
  embedChunks(
    chunks: Chunk[],
  ): Promise<Array<{ chunk: Chunk; embedding: number[] }>>;
}

/**
 * Interface for metadata storage operations.
 */
export interface IMetadataStore {
  insertFileMeta(files: FileMetadata[]): void;
  insertChunks(chunks: Chunk[]): void;
  searchFTS(query: string, limit: number): ScoredChunk[];
  getEmbeddingCache(cacheKey: string): number[] | null;
  setEmbeddingCache(cacheKey: string, embedding: number[]): void;
  close(): void;
}

/**
 * Interface for vector storage operations.
 */
export interface IVectorStore {
  initialize(): Promise<void>;
  insertBatch(
    docs: Array<{ chunk: Chunk; embedding: number[] }>,
  ): Promise<void>;
  query(
    queryVector: number[],
    topK: number,
    filter?: string,
  ): Promise<VectorSearchResult[]>;
  deleteByFilePath(filePath: string): Promise<void>;
  optimize(): void;
  destroy(): void;
}

// ===== é…ç½®ç±»å‹ =====
export interface IndexConfig {
  enabled: boolean; // æ€»å¼€å…³
  autoIndex: boolean; // æ˜¯å¦è‡ªåŠ¨ç´¢å¼•æ–°é¡¹ç›®
  pollIntervalMs: number; // å˜æ›´æ£€æµ‹é—´éš” (é»˜è®¤ 600000 = 10min)
  chunkMaxTokens: number; // æœ€å¤§ chunk token æ•° (é»˜è®¤ 512)
  chunkOverlapTokens: number; // chunk é‡å  token æ•° (é»˜è®¤ 50)
  embeddingBatchSize: number; // embedding æ‰¹é‡å¤§å° (é»˜è®¤ 20)
  embeddingBatchDelayMs: number; // æ‰¹æ¬¡é—´å»¶è¿Ÿ (é»˜è®¤ 100)
  streamThreshold: number; // è¶…è¿‡æ­¤æ–‡ä»¶æ•°ä½¿ç”¨æµå¼å¤„ç† (é»˜è®¤ 50000)
}

export interface RetrievalConfig {
  topK: number; // æœ€ç»ˆè¿”å›æ•°é‡ (é»˜è®¤ 20)
  bm25TopK: number; // BM25 å¬å›æ•°é‡ (é»˜è®¤ 50)
  vectorTopK: number; // å‘é‡å¬å›æ•°é‡ (é»˜è®¤ 50)
  recentTopK: number; // æœ€è¿‘ç¼–è¾‘å¬å› (é»˜è®¤ 20)
  rrfK: number; // RRF å‚æ•° (é»˜è®¤ 60)
  maxTokens: number; // ä¸Šä¸‹æ–‡ token é™åˆ¶ (é»˜è®¤ 8000)
  weights: {
    bm25: number; // é»˜è®¤ 1.0
    vector: number; // é»˜è®¤ 1.0
    recent: number; // é»˜è®¤ 0.5
  };
}

// ===== æ•°æ®ç±»å‹ =====
export interface FileMetadata {
  path: string;
  contentHash: string;
  lastModified: number;
  size: number;
  language?: string;
}

export type ChunkType =
  | 'function'
  | 'class'
  | 'method'
  | 'interface'
  | 'module'
  | 'import'
  | 'config'
  | 'block';

export interface ChunkMetadata {
  language: string;
  functionName?: string;
  className?: string;
  imports?: string[];
  exports?: string[];
  signature?: string;
}

export interface Chunk {
  id: string;
  filepath: string;
  content: string;
  startLine: number;
  endLine: number;
  index: number;
  contentHash: string;
  type: ChunkType;
  metadata: ChunkMetadata;
}

// ===== çŠ¶æ€ç±»å‹ =====
export type IndexStatus =
  | 'idle'
  | 'scanning'
  | 'chunking'
  | 'embedding'
  | 'storing'
  | 'done'
  | 'paused'
  | 'error';

export interface IndexingProgress {
  status: IndexStatus;
  phase: number;
  phaseProgress: number;
  overallProgress: number;
  scannedFiles: number;
  totalFiles: number;
  chunkedFiles: number;
  embeddedChunks: number;
  totalChunks: number;
  storedChunks: number;
  startTime: number;
  estimatedTimeRemaining?: number;
  error?: string;
  failedFiles?: string[];
}

// ===== å˜æ›´ç±»å‹ =====
export interface ChangeSet {
  added: FileMetadata[];
  modified: FileMetadata[];
  deleted: string[];
}

// ===== æ£€ç´¢ç±»å‹ =====
export interface ScoredChunk {
  id: string;
  filePath: string;
  content: string;
  startLine: number;
  endLine: number;
  score: number;
  rank: number;
  source: 'bm25' | 'vector' | 'recent';
}

export interface RetrievalResult extends ScoredChunk {
  fusedScore: number;
}

// ===== æ–­ç‚¹ç»­ä¼ ç±»å‹ =====
export interface BuildCheckpoint {
  phase: IndexStatus;
  lastProcessedPath: string | null;
  pendingChunkIds: string[];
  updatedAt: number;
}

// ===== Worker æ¶ˆæ¯ç±»å‹ =====
export type WorkerMessage =
  | { type: 'build'; payload: { resumeFromCheckpoint?: boolean } }
  | { type: 'incremental_update'; payload: { changes?: ChangeSet } }
  | { type: 'pause' }
  | { type: 'resume' }
  | { type: 'cancel' }
  | { type: 'get_status' };

export type WorkerResponse =
  | { type: 'progress'; payload: IndexingProgress }
  | { type: 'build_complete' }
  | { type: 'update_complete' }
  | { type: 'paused' }
  | { type: 'resumed' }
  | { type: 'cancelled' }
  | { type: 'status'; payload: IndexingProgress }
  | { type: 'error'; payload: { message: string } };
```

### B. é»˜è®¤é…ç½®

```typescript
// packages/core/src/indexing/defaults.ts

export const DEFAULT_INDEX_CONFIG: IndexConfig = {
  enabled: true,
  autoIndex: true,
  pollIntervalMs: 10 * 60 * 1000, // 10 minutes
  chunkMaxTokens: 512,
  chunkOverlapTokens: 50,
  embeddingBatchSize: 20,
  embeddingBatchDelayMs: 100,
  streamThreshold: 50_000, // è¶…è¿‡ 5 ä¸‡æ–‡ä»¶ä½¿ç”¨æµå¼å¤„ç†
};

export const DEFAULT_RETRIEVAL_CONFIG: RetrievalConfig = {
  topK: 20,
  bm25TopK: 50,
  vectorTopK: 50,
  recentTopK: 20,
  rrfK: 60,
  maxTokens: 8000,
  weights: {
    bm25: 1.0,
    vector: 1.0,
    recent: 0.5,
  },
};
```

### C. ç”¨æˆ·é…ç½®ç¤ºä¾‹

```json
// .qwen/settings.json
{
  "codebaseIndex": {
    "enabled": true,
    "autoIndex": true,
    "pollIntervalMinutes": 10,
    "graph": {
      "enabled": true,
      "maxDepth": 2,
      "maxNodes": 50
    },
    "retrieval": {
      "topK": 20,
      "enableGraph": true,
      "weights": {
        "bm25": 1.0,
        "vector": 1.0,
        "recent": 0.5
      }
    },
    "exclude": ["**/*.min.js", "**/vendor/**", "**/dist/**"]
  }
}
```

### D. ç›®å½•ç»“æ„

```
packages/core/src/indexing/
â”œâ”€â”€ types.ts                    # ç±»å‹å®šä¹‰ï¼ˆå«å›¾è°±ç±»å‹ï¼‰
â”œâ”€â”€ defaults.ts                 # é»˜è®¤é…ç½®
â”œâ”€â”€ indexService.ts             # ä¸»çº¿ç¨‹æœåŠ¡é—¨é¢
â”œâ”€â”€ indexManager.ts             # Worker å†…ç´¢å¼•ç®¡ç†å™¨
â”œâ”€â”€ fileScanner.ts              # æ–‡ä»¶æ‰«æï¼ˆå¤ç”¨ FileDiscoveryService + ripgrepUtilsï¼‰
â”œâ”€â”€ chunkingService.ts          # ä»£ç åˆ†å—æœåŠ¡
â”œâ”€â”€ entityExtractor.ts          # AST å®ä½“æå–ï¼ˆå‡½æ•°/ç±»/æ¨¡å—/è°ƒç”¨/ç»§æ‰¿/å¯¼å…¥ï¼‰
â”œâ”€â”€ embeddingService.ts         # Embedding ç”ŸæˆæœåŠ¡
â”œâ”€â”€ embeddingCache.ts           # Embedding ç¼“å­˜
â”œâ”€â”€ changeDetector.ts           # å˜æ›´æ£€æµ‹
â”œâ”€â”€ branchHandler.ts            # åˆ†æ”¯åˆ‡æ¢å¤„ç†
â”œâ”€â”€ retrievalService.ts         # æ£€ç´¢æœåŠ¡ï¼ˆå«å›¾æ‰©å±•ï¼‰
â”œâ”€â”€ graphTraverser.ts           # å›¾éå†ä¸å­å›¾æå–
â”œâ”€â”€ queryEnhancer.ts            # æŸ¥è¯¢å¢å¼º
â”œâ”€â”€ contextBuilder.ts           # ä¸Šä¸‹æ–‡æ„å»ºï¼ˆText + Graph è§†å›¾ï¼‰
â”œâ”€â”€ checkpointManager.ts        # æ–­ç‚¹ç»­ä¼ ç®¡ç†
â”œâ”€â”€ stores/
â”‚   â”œâ”€â”€ metadataStore.ts        # SQLite å…ƒæ•°æ®å­˜å‚¨
â”‚   â”œâ”€â”€ vectorStore.ts          # Zvec å‘é‡å­˜å‚¨
â”‚   â””â”€â”€ graphStore.ts           # @ruvector/graph-node å›¾æ•°æ®åº“å­˜å‚¨
â””â”€â”€ worker/
    â””â”€â”€ indexWorker.ts          # Worker Thread å…¥å£

packages/cli/src/
â”œâ”€â”€ services/
â”‚   â””â”€â”€ CodebaseCommandLoader.ts  # å‘½ä»¤åŠ è½½å™¨ï¼ˆéµå¾ªç°æœ‰ Loader å‘½åï¼‰
â”œâ”€â”€ ui/commands/
â”‚   â””â”€â”€ codebaseCommand.ts        # /codebase å‘½ä»¤
â””â”€â”€ ui/components/
    â””â”€â”€ IndexStatus.tsx           # ç´¢å¼•çŠ¶æ€ UIï¼ˆReact ç»„ä»¶ç”¨ PascalCaseï¼‰
```

---

## 10. ç‰ˆæœ¬å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ       | å˜æ›´å†…å®¹                                                                                                                                                                    |
| ---- | ---------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| v1.0 | 2026-01-27 | åˆå§‹ç‰ˆæœ¬                                                                                                                                                                    |
| v1.1 | 2026-01-28 | æ¶æ„é£æ ¼å¯¹é½ qwen-code ç°æœ‰è®¾è®¡ï¼›ä¼˜åŒ–å˜æ›´æ£€æµ‹ç­–ç•¥ï¼ˆçº¯è½®è¯¢ï¼‰ï¼›å¢åŠ  embedding ç¼“å­˜é”®ä¼˜åŒ–ï¼›å¢åŠ æ–­ç‚¹ç»­ä¼ æœºåˆ¶ï¼›æ€§èƒ½ä¼˜åŒ–èå…¥å„æ­¥éª¤ï¼›å®Œå–„æ¥å£å®šä¹‰å’Œç›®å½•ç»“æ„                        |
| v1.2 | 2026-01-28 | æ˜ç¡®å¹³å°æ”¯æŒèŒƒå›´ï¼ˆä»… macOS/Linuxï¼‰ï¼›åœ¨åŠŸèƒ½å…¥å£å¤„è¿›è¡Œå¹³å°æ ¡éªŒ                                                                                                                |
| v1.3 | 2026-01-28 | æ–°å¢çŸ¥è¯†å›¾è°±ï¼ˆä¾èµ–å›¾ï¼‰åŠŸèƒ½ï¼šåŸºäº AST è‡ªåŠ¨æå–å®ä½“ä¸å…³ç³»ï¼Œä½¿ç”¨åµŒå…¥å¼å›¾æ•°æ®åº“å­˜å‚¨ï¼›æ£€ç´¢æ—¶ä»ç§å­å—æ²¿ä¾èµ–å…³ç³»å¤šè·³æ‰©å±•æå–æœ€å°å®Œå¤‡å­å›¾ï¼›è¿”å› Text View + Graph View åŒè§†å›¾       |
| v1.4 | 2026-01-29 | **å¤ç”¨ä¼˜åŒ–**ï¼šå¹³å°æ£€æŸ¥å¤ç”¨å·²æœ‰ `isWindows` å·¥å…·è€Œéæ–°å»ºæ¨¡å—ï¼›FileScanner å¤ç”¨ `FileDiscoveryService` + `ripgrepUtils`ï¼›å›¾æ•°æ®åº“ä» Kuzuï¼ˆå·²å½’æ¡£ï¼‰æ”¹ä¸º `@ruvector/graph-node` |
